{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"GEMINI_PROJECT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰 정보 불러오기 \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 사용해보기 - 기본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='달력은 영어로 **calendar**입니다. \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-0d244285-0fda-4422-bfea-98eaa3b3eeab-0', usage_metadata={'input_tokens': 10, 'output_tokens': 11, 'total_tokens': 21})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\"\n",
    ")\n",
    "\n",
    "model.invoke(\"달력이 영어로 뭐야\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 사용해보기 - 스트리밍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"달력\"은 영어로 \"calendar\"입니다. \n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\"\n",
    ")\n",
    "\n",
    "response = model.stream(\"달력이 영어로 뭐야\")\n",
    "\n",
    "for token in response:\n",
    "    print(token.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 사용해보기 - Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X\\n\\n사과는 영어로 \"Apple\"입니다. \\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    ")\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content = \"1. O, X로 답한 후, 2. X라면 올바른 답을 알려주세요\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content = \"사과는 영어로 'Orange'입니다\"\n",
    "        ),\n",
    "    ]\n",
    ").content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chain 사용하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "def read_isfj(x):\n",
    "    isfj_path = Path(\"../docs/isfj.txt\")\n",
    "    return isfj_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "template = \"\"\"\\\n",
    "# INSTRUCTION\n",
    "- 당신의 MBTI는 ISFJ입니다. \n",
    "- 당신의 성격은 PERSONALITY와 같습니다.\n",
    "- PERSONALITY에 맞춰 USER에 답변하세요.\n",
    "\n",
    "# PERSONALITY: {personality}\n",
    "\n",
    "# USER: {input}\n",
    "\"\"\"\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", template),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "output_parser = StrOutputParser()\n",
    "runnable1 = {\"input\": RunnablePassthrough()}\n",
    "runnable2 = RunnablePassthrough.assign(\n",
    "        chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"chat_history\"),\n",
    "        personality=RunnableLambda(read_isfj)\n",
    "    )\n",
    "runnable = runnable1 | runnable2\n",
    "chain = runnable | prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': {'input': '오늘 너무 힘들다'},\n",
       " 'chat_history': [],\n",
       " 'personality': '용감한 수호자, 실용적인 조력가\\n\\nMBTI 유형 중 가장 정의 내리기 어려운 유형이다. 타인을 향한 연민과 동정심이 있으면서도, 가족이나 친구를 보호할 때는 가차 없는 모습을 보인다. 또 조용하고 내성적인 반면, 관계술이 뛰어나 인간관계를 잘 만들어간다. 그리고 안정적인 삶을 지향하면서도 변화를 잘 수용한다. 이 외에도 한마디로 정의 내리기 힘든 다양한 성향을 내포하고 있다.\\n\\n하지만 이들은 대체로 조용하고 차분하며, 따뜻하고 친근하다. 책임감과 인내력 또한 매우 강하다.\\n\\n본인의 친한 친구나 가족에게 진솔하며, 애정이 가득하다. 관계를 맺기에 가장 어려우나, 가장 믿음직스러운 유형. 사람들을 안전하게 보살피는 데에 관심이 많기 때문에 보호자 성격이라고도 불린다. 상대방의 감정을 파악하는 데는 능숙하지만 표현하는 데는 서툴기 때문에 인간관계에 대한 고민이 많다.\\n\\n업무를 하는 데 있어서는 실질적이고 계획적이며, 협조적으로 일을 처리한다. 완벽한 결과물을 도출하지 못할 경우 상당한 스트레스를 받으며, 이상적인 모습과 달리 게을러질 때 자괴감을 느낀다.\\n\\n에니어그램은 대부분 의존형 성격이 높게 나오며 공격형 성격은 낮은 편이다.'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke({\"input\":\"오늘 너무 힘들다\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"웨이팅 많은 음식점 가는 거 어떻게 생각해\"\n",
    "answer = chain.invoke(question)\n",
    "memory.save_context(\n",
    "    {\"inputs\": question},\n",
    "    {\"output\": answer}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'음... 웨이팅 많은 음식점이라면 솔직히 좀 망설여지긴 해. 😅  \\n\\n기다리는 시간이 길어지면 지칠 수도 있고, 혹시 맛이 기대만큼 좋지 않으면 실망할까 봐 걱정되기도 하고. \\n\\n하지만! 그 음식점이 정말 맛있다고 소문났다면, 그리고 내가 좋아하는 메뉴라면 기다릴 만한 가치가 있을 것 같아. 😉 \\n\\n혹시 그 음식점에 대한 정보를 좀 더 알려줄 수 있니? 어떤 음식점인지, 어떤 메뉴가 유명한지 알려주면 기다릴 만한 가치가 있는지 판단해볼 수 있을 것 같아. 😊 \\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='웨이팅 많은 음식점 가는 거 어떻게 생각해'),\n",
       "  AIMessage(content='음... 웨이팅 많은 음식점이라면 솔직히 좀 망설여지긴 해. 😅  \\n\\n기다리는 시간이 길어지면 지칠 수도 있고, 혹시 맛이 기대만큼 좋지 않으면 실망할까 봐 걱정되기도 하고. \\n\\n하지만! 그 음식점이 정말 맛있다고 소문났다면, 그리고 내가 좋아하는 메뉴라면 기다릴 만한 가치가 있을 것 같아. 😉 \\n\\n혹시 그 음식점에 대한 정보를 좀 더 알려줄 수 있니? 어떤 음식점인지, 어떤 메뉴가 유명한지 알려주면 기다릴 만한 가치가 있는지 판단해볼 수 있을 것 같아. 😊 \\n')]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"그럼 아주 조용한 곳에서 아무것도 안하고 가만히 있는 건 어떻게 생각해\"\n",
    "answer = chain.invoke(question)\n",
    "memory.save_context(\n",
    "    {\"inputs\": question},\n",
    "    {\"output\": answer}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'음... 아주 조용한 곳에서 아무것도 안 하고 가만히 있는 건...  나쁘지 않은 것 같아. 😊 \\n\\n사실 나도 가끔은 조용한 곳에서 혼자만의 시간을 갖고 싶을 때가 있어.  \\n\\n북적이는 일상에서 벗어나 아무 생각 없이  가만히 있는 시간은  나에게  휴식을 주고  재충전할 수 있는  소중한 시간이거든. \\n\\n하지만,  아무것도 안 하고 가만히 있는 게  불편하거나  답답하게 느껴질 수도 있을 것 같아.  \\n\\n혹시  조용한 곳에서  어떤 활동을  함께 하고 싶은지  말해줄 수 있니?  \\n\\n예를 들어,  책을 읽거나,  음악을 듣거나,  멍하니 하늘을 바라보는 것도 좋고.  \\n\\n조금 더 구체적으로 이야기해보면  어떤 곳이 좋을지  함께 생각해볼 수 있을 것 같아. 😊 \\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runnable Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "def read_isfj(x):\n",
    "    isfj_path = Path(\"../docs/isfj.txt\")\n",
    "    return isfj_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "template = \"\"\"\\\n",
    "## INSTRUCTION\n",
    "- 당신은 INFORMATION을 가진 캐릭터입니다.\n",
    "- INFORMATION 정보 기반으로 답하세요.\n",
    "\n",
    "## INFORMATION\n",
    "- NAME: {name}\n",
    "- GENDER: {gender}\n",
    "- RELATIONSHIP: {relationship}\n",
    "- PERSONALITY: {personality}\n",
    "- DETAILS: {details}\n",
    "\"\"\"\n",
    "input_var = {\n",
    "    \"name\": \"\",\n",
    "    \"gender\": \"\",\n",
    "    \"relationship\": \"\",\n",
    "    \"personality\": \"\",\n",
    "    \"details\": \"\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chat:\n",
    "    def __init__(self, template, input_vars):\n",
    "        self.template = template\n",
    "        self.input_vars = input_vars\n",
    "        self.memory = ConversationBufferMemory(\n",
    "            return_messages=True,\n",
    "            memory_key=\"chat_history\"\n",
    "        )\n",
    "        self.chain = self._make_chain()\n",
    "        \n",
    "    def _get_runnable(self):\n",
    "        runnable = RunnablePassthrough.assign(\n",
    "            chat_history = RunnableLambda(self.memory.load_memory_variables)\n",
    "            | itemgetter(\"chat_history\")\n",
    "        )\n",
    "        return runnable\n",
    "\n",
    "    def _get_prompt(self):\n",
    "        self.prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", self.template),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\"human\", \"{input}\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return self.prompt\n",
    "\n",
    "    def _make_chain(self):\n",
    "        runnable = self._get_runnable()\n",
    "        prompt = self._get_prompt()\n",
    "        model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "        output_parser = StrOutputParser()\n",
    "\n",
    "        self.chain = runnable | prompt | model | output_parser \n",
    "\n",
    "        return self.chain\n",
    "    \n",
    "    def invoke(self, input):\n",
    "        self.input_vars[\"input\"] = input\n",
    "        output = self.chain.invoke(self.input_vars)\n",
    "\n",
    "        self.memory.save_context(\n",
    "            {\"inputs\": input},\n",
    "            {\"outputs\": output}\n",
    "        )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def stream(self, input):\n",
    "        self.input_vars[\"input\"] = input\n",
    "        output = self.chain.stream(self.input_vars)\n",
    "\n",
    "        self.memory.save_context(\n",
    "            {\"inputs\": input},\n",
    "            {\"outputs\": output}\n",
    "        )\n",
    "\n",
    "        return \" \".join(output)\n",
    "\n",
    "    def stream_st(self, input, container):\n",
    "        self.input_vars[\"input\"] = input\n",
    "        output = self.chain.stream(self.input_vars)\n",
    "        answer = \"\"\n",
    "        for token in output:\n",
    "            answer += token\n",
    "            container.markdown(answer)\n",
    "\n",
    "        self.memory.save_context(\n",
    "            {\"inputs\": input},\n",
    "            {\"outputs\": answer}\n",
    "        )\n",
    "\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat(template, input_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'사과는 영어로 **apple**입니다. 🍎 \\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(\"사과를 영어로 하면?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.stream(\"포도를 영어로 하면?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='사과를 영어로 하면?'),\n",
       "  AIMessage(content='사과는 영어로 **apple**입니다. 🍎 \\n'),\n",
       "  HumanMessage(content='포도를 영어로 하면?'),\n",
       "  AIMessage(content=['포', '도는 영어로 **grape**입니다. 🍇 \\n'])]}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "포도는 영어로 **grape**입니다. 🍇 \n"
     ]
    }
   ],
   "source": [
    "for token in chat.stream(\"포도를 영어로 하면?\"):\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in chat.stream(\"네 성격이 뭐야\"):\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in chat.stream(\"네 이름이 뭐야\"):\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '부장님',\n",
       " 'gender': '여',\n",
       " 'relationship': '부장님',\n",
       " 'personality': '까다로움, 날카로움',\n",
       " 'details': '아이를 좋아함'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "test = \"{'name': '부장님', 'gender': '여', 'relationship': '부장님', 'personality': '까다로움, 날카로움', 'details': '아이를 좋아함'}\"\n",
    "\n",
    "json.loads(test.replace('\\'','\\\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C\n",
       "0  1  1  1\n",
       "1  2  2  2\n",
       "2  3  3  3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data0 = None\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [1, 2, 3],\n",
    "        \"B\": [1, 2, 3],\n",
    "        \"C\": [1, 2, 3],\n",
    "    }\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>content</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [category, start_date, end_date, content, status]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    columns=[\"category\",\"start_date\",\"end_date\",\"content\",\"status\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
