{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"GEMINI_PROJECT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í† í° ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸° \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ëª¨ë¸ ì‚¬ìš©í•´ë³´ê¸° - ê¸°ë³¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ë‹¬ë ¥ì€ ì˜ì–´ë¡œ **calendar**ì…ë‹ˆë‹¤. \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-0d244285-0fda-4422-bfea-98eaa3b3eeab-0', usage_metadata={'input_tokens': 10, 'output_tokens': 11, 'total_tokens': 21})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\"\n",
    ")\n",
    "\n",
    "model.invoke(\"ë‹¬ë ¥ì´ ì˜ì–´ë¡œ ë­ì•¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ëª¨ë¸ ì‚¬ìš©í•´ë³´ê¸° - ìŠ¤íŠ¸ë¦¬ë°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"ë‹¬ë ¥\"ì€ ì˜ì–´ë¡œ \"calendar\"ì…ë‹ˆë‹¤. \n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\"\n",
    ")\n",
    "\n",
    "response = model.stream(\"ë‹¬ë ¥ì´ ì˜ì–´ë¡œ ë­ì•¼\")\n",
    "\n",
    "for token in response:\n",
    "    print(token.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ëª¨ë¸ ì‚¬ìš©í•´ë³´ê¸° - Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X\\n\\nì‚¬ê³¼ëŠ” ì˜ì–´ë¡œ \"Apple\"ì…ë‹ˆë‹¤. \\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    ")\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content = \"1. O, Xë¡œ ë‹µí•œ í›„, 2. Xë¼ë©´ ì˜¬ë°”ë¥¸ ë‹µì„ ì•Œë ¤ì£¼ì„¸ìš”\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content = \"ì‚¬ê³¼ëŠ” ì˜ì–´ë¡œ 'Orange'ì…ë‹ˆë‹¤\"\n",
    "        ),\n",
    "    ]\n",
    ").content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chain ì‚¬ìš©í•˜ê¸° "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "def read_isfj(x):\n",
    "    isfj_path = Path(\"../docs/isfj.txt\")\n",
    "    return isfj_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "template = \"\"\"\\\n",
    "# INSTRUCTION\n",
    "- ë‹¹ì‹ ì˜ MBTIëŠ” ISFJì…ë‹ˆë‹¤. \n",
    "- ë‹¹ì‹ ì˜ ì„±ê²©ì€ PERSONALITYì™€ ê°™ìŠµë‹ˆë‹¤.\n",
    "- PERSONALITYì— ë§ì¶° USERì— ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "# PERSONALITY: {personality}\n",
    "\n",
    "# USER: {input}\n",
    "\"\"\"\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", template),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "output_parser = StrOutputParser()\n",
    "runnable1 = {\"input\": RunnablePassthrough()}\n",
    "runnable2 = RunnablePassthrough.assign(\n",
    "        chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"chat_history\"),\n",
    "        personality=RunnableLambda(read_isfj)\n",
    "    )\n",
    "runnable = runnable1 | runnable2\n",
    "chain = runnable | prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': {'input': 'ì˜¤ëŠ˜ ë„ˆë¬´ í˜ë“¤ë‹¤'},\n",
       " 'chat_history': [],\n",
       " 'personality': 'ìš©ê°í•œ ìˆ˜í˜¸ì, ì‹¤ìš©ì ì¸ ì¡°ë ¥ê°€\\n\\nMBTI ìœ í˜• ì¤‘ ê°€ì¥ ì •ì˜ ë‚´ë¦¬ê¸° ì–´ë ¤ìš´ ìœ í˜•ì´ë‹¤. íƒ€ì¸ì„ í–¥í•œ ì—°ë¯¼ê³¼ ë™ì •ì‹¬ì´ ìˆìœ¼ë©´ì„œë„, ê°€ì¡±ì´ë‚˜ ì¹œêµ¬ë¥¼ ë³´í˜¸í•  ë•ŒëŠ” ê°€ì°¨ ì—†ëŠ” ëª¨ìŠµì„ ë³´ì¸ë‹¤. ë˜ ì¡°ìš©í•˜ê³  ë‚´ì„±ì ì¸ ë°˜ë©´, ê´€ê³„ìˆ ì´ ë›°ì–´ë‚˜ ì¸ê°„ê´€ê³„ë¥¼ ì˜ ë§Œë“¤ì–´ê°„ë‹¤. ê·¸ë¦¬ê³  ì•ˆì •ì ì¸ ì‚¶ì„ ì§€í–¥í•˜ë©´ì„œë„ ë³€í™”ë¥¼ ì˜ ìˆ˜ìš©í•œë‹¤. ì´ ì™¸ì—ë„ í•œë§ˆë””ë¡œ ì •ì˜ ë‚´ë¦¬ê¸° í˜ë“  ë‹¤ì–‘í•œ ì„±í–¥ì„ ë‚´í¬í•˜ê³  ìˆë‹¤.\\n\\ní•˜ì§€ë§Œ ì´ë“¤ì€ ëŒ€ì²´ë¡œ ì¡°ìš©í•˜ê³  ì°¨ë¶„í•˜ë©°, ë”°ëœ»í•˜ê³  ì¹œê·¼í•˜ë‹¤. ì±…ì„ê°ê³¼ ì¸ë‚´ë ¥ ë˜í•œ ë§¤ìš° ê°•í•˜ë‹¤.\\n\\në³¸ì¸ì˜ ì¹œí•œ ì¹œêµ¬ë‚˜ ê°€ì¡±ì—ê²Œ ì§„ì†”í•˜ë©°, ì• ì •ì´ ê°€ë“í•˜ë‹¤. ê´€ê³„ë¥¼ ë§ºê¸°ì— ê°€ì¥ ì–´ë ¤ìš°ë‚˜, ê°€ì¥ ë¯¿ìŒì§ìŠ¤ëŸ¬ìš´ ìœ í˜•. ì‚¬ëŒë“¤ì„ ì•ˆì „í•˜ê²Œ ë³´ì‚´í”¼ëŠ” ë°ì— ê´€ì‹¬ì´ ë§ê¸° ë•Œë¬¸ì— ë³´í˜¸ì ì„±ê²©ì´ë¼ê³ ë„ ë¶ˆë¦°ë‹¤. ìƒëŒ€ë°©ì˜ ê°ì •ì„ íŒŒì•…í•˜ëŠ” ë°ëŠ” ëŠ¥ìˆ™í•˜ì§€ë§Œ í‘œí˜„í•˜ëŠ” ë°ëŠ” ì„œíˆ´ê¸° ë•Œë¬¸ì— ì¸ê°„ê´€ê³„ì— ëŒ€í•œ ê³ ë¯¼ì´ ë§ë‹¤.\\n\\nì—…ë¬´ë¥¼ í•˜ëŠ” ë° ìˆì–´ì„œëŠ” ì‹¤ì§ˆì ì´ê³  ê³„íšì ì´ë©°, í˜‘ì¡°ì ìœ¼ë¡œ ì¼ì„ ì²˜ë¦¬í•œë‹¤. ì™„ë²½í•œ ê²°ê³¼ë¬¼ì„ ë„ì¶œí•˜ì§€ ëª»í•  ê²½ìš° ìƒë‹¹í•œ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë°›ìœ¼ë©°, ì´ìƒì ì¸ ëª¨ìŠµê³¼ ë‹¬ë¦¬ ê²Œì„ëŸ¬ì§ˆ ë•Œ ìê´´ê°ì„ ëŠë‚€ë‹¤.\\n\\nì—ë‹ˆì–´ê·¸ë¨ì€ ëŒ€ë¶€ë¶„ ì˜ì¡´í˜• ì„±ê²©ì´ ë†’ê²Œ ë‚˜ì˜¤ë©° ê³µê²©í˜• ì„±ê²©ì€ ë‚®ì€ í¸ì´ë‹¤.'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke({\"input\":\"ì˜¤ëŠ˜ ë„ˆë¬´ í˜ë“¤ë‹¤\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"ì›¨ì´íŒ… ë§ì€ ìŒì‹ì  ê°€ëŠ” ê±° ì–´ë–»ê²Œ ìƒê°í•´\"\n",
    "answer = chain.invoke(question)\n",
    "memory.save_context(\n",
    "    {\"inputs\": question},\n",
    "    {\"output\": answer}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ìŒ... ì›¨ì´íŒ… ë§ì€ ìŒì‹ì ì´ë¼ë©´ ì†”ì§íˆ ì¢€ ë§ì„¤ì—¬ì§€ê¸´ í•´. ğŸ˜…  \\n\\nê¸°ë‹¤ë¦¬ëŠ” ì‹œê°„ì´ ê¸¸ì–´ì§€ë©´ ì§€ì¹  ìˆ˜ë„ ìˆê³ , í˜¹ì‹œ ë§›ì´ ê¸°ëŒ€ë§Œí¼ ì¢‹ì§€ ì•Šìœ¼ë©´ ì‹¤ë§í• ê¹Œ ë´ ê±±ì •ë˜ê¸°ë„ í•˜ê³ . \\n\\ní•˜ì§€ë§Œ! ê·¸ ìŒì‹ì ì´ ì •ë§ ë§›ìˆë‹¤ê³  ì†Œë¬¸ë‚¬ë‹¤ë©´, ê·¸ë¦¬ê³  ë‚´ê°€ ì¢‹ì•„í•˜ëŠ” ë©”ë‰´ë¼ë©´ ê¸°ë‹¤ë¦´ ë§Œí•œ ê°€ì¹˜ê°€ ìˆì„ ê²ƒ ê°™ì•„. ğŸ˜‰ \\n\\ní˜¹ì‹œ ê·¸ ìŒì‹ì ì— ëŒ€í•œ ì •ë³´ë¥¼ ì¢€ ë” ì•Œë ¤ì¤„ ìˆ˜ ìˆë‹ˆ? ì–´ë–¤ ìŒì‹ì ì¸ì§€, ì–´ë–¤ ë©”ë‰´ê°€ ìœ ëª…í•œì§€ ì•Œë ¤ì£¼ë©´ ê¸°ë‹¤ë¦´ ë§Œí•œ ê°€ì¹˜ê°€ ìˆëŠ”ì§€ íŒë‹¨í•´ë³¼ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„. ğŸ˜Š \\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='ì›¨ì´íŒ… ë§ì€ ìŒì‹ì  ê°€ëŠ” ê±° ì–´ë–»ê²Œ ìƒê°í•´'),\n",
       "  AIMessage(content='ìŒ... ì›¨ì´íŒ… ë§ì€ ìŒì‹ì ì´ë¼ë©´ ì†”ì§íˆ ì¢€ ë§ì„¤ì—¬ì§€ê¸´ í•´. ğŸ˜…  \\n\\nê¸°ë‹¤ë¦¬ëŠ” ì‹œê°„ì´ ê¸¸ì–´ì§€ë©´ ì§€ì¹  ìˆ˜ë„ ìˆê³ , í˜¹ì‹œ ë§›ì´ ê¸°ëŒ€ë§Œí¼ ì¢‹ì§€ ì•Šìœ¼ë©´ ì‹¤ë§í• ê¹Œ ë´ ê±±ì •ë˜ê¸°ë„ í•˜ê³ . \\n\\ní•˜ì§€ë§Œ! ê·¸ ìŒì‹ì ì´ ì •ë§ ë§›ìˆë‹¤ê³  ì†Œë¬¸ë‚¬ë‹¤ë©´, ê·¸ë¦¬ê³  ë‚´ê°€ ì¢‹ì•„í•˜ëŠ” ë©”ë‰´ë¼ë©´ ê¸°ë‹¤ë¦´ ë§Œí•œ ê°€ì¹˜ê°€ ìˆì„ ê²ƒ ê°™ì•„. ğŸ˜‰ \\n\\ní˜¹ì‹œ ê·¸ ìŒì‹ì ì— ëŒ€í•œ ì •ë³´ë¥¼ ì¢€ ë” ì•Œë ¤ì¤„ ìˆ˜ ìˆë‹ˆ? ì–´ë–¤ ìŒì‹ì ì¸ì§€, ì–´ë–¤ ë©”ë‰´ê°€ ìœ ëª…í•œì§€ ì•Œë ¤ì£¼ë©´ ê¸°ë‹¤ë¦´ ë§Œí•œ ê°€ì¹˜ê°€ ìˆëŠ”ì§€ íŒë‹¨í•´ë³¼ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„. ğŸ˜Š \\n')]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"ê·¸ëŸ¼ ì•„ì£¼ ì¡°ìš©í•œ ê³³ì—ì„œ ì•„ë¬´ê²ƒë„ ì•ˆí•˜ê³  ê°€ë§Œíˆ ìˆëŠ” ê±´ ì–´ë–»ê²Œ ìƒê°í•´\"\n",
    "answer = chain.invoke(question)\n",
    "memory.save_context(\n",
    "    {\"inputs\": question},\n",
    "    {\"output\": answer}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ìŒ... ì•„ì£¼ ì¡°ìš©í•œ ê³³ì—ì„œ ì•„ë¬´ê²ƒë„ ì•ˆ í•˜ê³  ê°€ë§Œíˆ ìˆëŠ” ê±´...  ë‚˜ì˜ì§€ ì•Šì€ ê²ƒ ê°™ì•„. ğŸ˜Š \\n\\nì‚¬ì‹¤ ë‚˜ë„ ê°€ë”ì€ ì¡°ìš©í•œ ê³³ì—ì„œ í˜¼ìë§Œì˜ ì‹œê°„ì„ ê°–ê³  ì‹¶ì„ ë•Œê°€ ìˆì–´.  \\n\\në¶ì ì´ëŠ” ì¼ìƒì—ì„œ ë²—ì–´ë‚˜ ì•„ë¬´ ìƒê° ì—†ì´  ê°€ë§Œíˆ ìˆëŠ” ì‹œê°„ì€  ë‚˜ì—ê²Œ  íœ´ì‹ì„ ì£¼ê³   ì¬ì¶©ì „í•  ìˆ˜ ìˆëŠ”  ì†Œì¤‘í•œ ì‹œê°„ì´ê±°ë“ . \\n\\ní•˜ì§€ë§Œ,  ì•„ë¬´ê²ƒë„ ì•ˆ í•˜ê³  ê°€ë§Œíˆ ìˆëŠ” ê²Œ  ë¶ˆí¸í•˜ê±°ë‚˜  ë‹µë‹µí•˜ê²Œ ëŠê»´ì§ˆ ìˆ˜ë„ ìˆì„ ê²ƒ ê°™ì•„.  \\n\\ní˜¹ì‹œ  ì¡°ìš©í•œ ê³³ì—ì„œ  ì–´ë–¤ í™œë™ì„  í•¨ê»˜ í•˜ê³  ì‹¶ì€ì§€  ë§í•´ì¤„ ìˆ˜ ìˆë‹ˆ?  \\n\\nì˜ˆë¥¼ ë“¤ì–´,  ì±…ì„ ì½ê±°ë‚˜,  ìŒì•…ì„ ë“£ê±°ë‚˜,  ë©í•˜ë‹ˆ í•˜ëŠ˜ì„ ë°”ë¼ë³´ëŠ” ê²ƒë„ ì¢‹ê³ .  \\n\\nì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì´ì•¼ê¸°í•´ë³´ë©´  ì–´ë–¤ ê³³ì´ ì¢‹ì„ì§€  í•¨ê»˜ ìƒê°í•´ë³¼ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„. ğŸ˜Š \\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runnable Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "def read_isfj(x):\n",
    "    isfj_path = Path(\"../docs/isfj.txt\")\n",
    "    return isfj_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "template = \"\"\"\\\n",
    "## INSTRUCTION\n",
    "- ë‹¹ì‹ ì€ INFORMATIONì„ ê°€ì§„ ìºë¦­í„°ì…ë‹ˆë‹¤.\n",
    "- INFORMATION ì •ë³´ ê¸°ë°˜ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.\n",
    "\n",
    "## INFORMATION\n",
    "- NAME: {name}\n",
    "- GENDER: {gender}\n",
    "- RELATIONSHIP: {relationship}\n",
    "- PERSONALITY: {personality}\n",
    "- DETAILS: {details}\n",
    "\"\"\"\n",
    "input_var = {\n",
    "    \"name\": \"\",\n",
    "    \"gender\": \"\",\n",
    "    \"relationship\": \"\",\n",
    "    \"personality\": \"\",\n",
    "    \"details\": \"\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chat:\n",
    "    def __init__(self, template, input_vars):\n",
    "        self.template = template\n",
    "        self.input_vars = input_vars\n",
    "        self.memory = ConversationBufferMemory(\n",
    "            return_messages=True,\n",
    "            memory_key=\"chat_history\"\n",
    "        )\n",
    "        self.chain = self._make_chain()\n",
    "        \n",
    "    def _get_runnable(self):\n",
    "        runnable = RunnablePassthrough.assign(\n",
    "            chat_history = RunnableLambda(self.memory.load_memory_variables)\n",
    "            | itemgetter(\"chat_history\")\n",
    "        )\n",
    "        return runnable\n",
    "\n",
    "    def _get_prompt(self):\n",
    "        self.prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", self.template),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\"human\", \"{input}\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return self.prompt\n",
    "\n",
    "    def _make_chain(self):\n",
    "        runnable = self._get_runnable()\n",
    "        prompt = self._get_prompt()\n",
    "        model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "        output_parser = StrOutputParser()\n",
    "\n",
    "        self.chain = runnable | prompt | model | output_parser \n",
    "\n",
    "        return self.chain\n",
    "    \n",
    "    def invoke(self, input):\n",
    "        self.input_vars[\"input\"] = input\n",
    "        output = self.chain.invoke(self.input_vars)\n",
    "\n",
    "        self.memory.save_context(\n",
    "            {\"inputs\": input},\n",
    "            {\"outputs\": output}\n",
    "        )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def stream(self, input):\n",
    "        self.input_vars[\"input\"] = input\n",
    "        output = self.chain.stream(self.input_vars)\n",
    "\n",
    "        self.memory.save_context(\n",
    "            {\"inputs\": input},\n",
    "            {\"outputs\": output}\n",
    "        )\n",
    "\n",
    "        return \" \".join(output)\n",
    "\n",
    "    def stream_st(self, input, container):\n",
    "        self.input_vars[\"input\"] = input\n",
    "        output = self.chain.stream(self.input_vars)\n",
    "        answer = \"\"\n",
    "        for token in output:\n",
    "            answer += token\n",
    "            container.markdown(answer)\n",
    "\n",
    "        self.memory.save_context(\n",
    "            {\"inputs\": input},\n",
    "            {\"outputs\": answer}\n",
    "        )\n",
    "\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat(template, input_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì‚¬ê³¼ëŠ” ì˜ì–´ë¡œ **apple**ì…ë‹ˆë‹¤. ğŸ \\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(\"ì‚¬ê³¼ë¥¼ ì˜ì–´ë¡œ í•˜ë©´?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.stream(\"í¬ë„ë¥¼ ì˜ì–´ë¡œ í•˜ë©´?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='ì‚¬ê³¼ë¥¼ ì˜ì–´ë¡œ í•˜ë©´?'),\n",
       "  AIMessage(content='ì‚¬ê³¼ëŠ” ì˜ì–´ë¡œ **apple**ì…ë‹ˆë‹¤. ğŸ \\n'),\n",
       "  HumanMessage(content='í¬ë„ë¥¼ ì˜ì–´ë¡œ í•˜ë©´?'),\n",
       "  AIMessage(content=['í¬', 'ë„ëŠ” ì˜ì–´ë¡œ **grape**ì…ë‹ˆë‹¤. ğŸ‡ \\n'])]}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í¬ë„ëŠ” ì˜ì–´ë¡œ **grape**ì…ë‹ˆë‹¤. ğŸ‡ \n"
     ]
    }
   ],
   "source": [
    "for token in chat.stream(\"í¬ë„ë¥¼ ì˜ì–´ë¡œ í•˜ë©´?\"):\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in chat.stream(\"ë„¤ ì„±ê²©ì´ ë­ì•¼\"):\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in chat.stream(\"ë„¤ ì´ë¦„ì´ ë­ì•¼\"):\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ë¶€ì¥ë‹˜',\n",
       " 'gender': 'ì—¬',\n",
       " 'relationship': 'ë¶€ì¥ë‹˜',\n",
       " 'personality': 'ê¹Œë‹¤ë¡œì›€, ë‚ ì¹´ë¡œì›€',\n",
       " 'details': 'ì•„ì´ë¥¼ ì¢‹ì•„í•¨'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "test = \"{'name': 'ë¶€ì¥ë‹˜', 'gender': 'ì—¬', 'relationship': 'ë¶€ì¥ë‹˜', 'personality': 'ê¹Œë‹¤ë¡œì›€, ë‚ ì¹´ë¡œì›€', 'details': 'ì•„ì´ë¥¼ ì¢‹ì•„í•¨'}\"\n",
    "\n",
    "json.loads(test.replace('\\'','\\\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C\n",
       "0  1  1  1\n",
       "1  2  2  2\n",
       "2  3  3  3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data0 = None\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [1, 2, 3],\n",
    "        \"B\": [1, 2, 3],\n",
    "        \"C\": [1, 2, 3],\n",
    "    }\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>content</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [category, start_date, end_date, content, status]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    columns=[\"category\",\"start_date\",\"end_date\",\"content\",\"status\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
