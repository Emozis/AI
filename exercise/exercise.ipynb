{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"GEMINI_PROJECT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í† í° ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸° \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ëª¨ë¸ ì‚¬ìš©í•´ë³´ê¸° - ê¸°ë³¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ë‹¬ë ¥ì€ ì˜ì–´ë¡œ **calendar**ì…ë‹ˆë‹¤. \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-0d244285-0fda-4422-bfea-98eaa3b3eeab-0', usage_metadata={'input_tokens': 10, 'output_tokens': 11, 'total_tokens': 21})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\"\n",
    ")\n",
    "\n",
    "model.invoke(\"ë‹¬ë ¥ì´ ì˜ì–´ë¡œ ë­ì•¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ëª¨ë¸ ì‚¬ìš©í•´ë³´ê¸° - ìŠ¤íŠ¸ë¦¬ë°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"ë‹¬ë ¥\"ì€ ì˜ì–´ë¡œ \"calendar\"ì…ë‹ˆë‹¤. \n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\"\n",
    ")\n",
    "\n",
    "response = model.stream(\"ë‹¬ë ¥ì´ ì˜ì–´ë¡œ ë­ì•¼\")\n",
    "\n",
    "for token in response:\n",
    "    print(token.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ëª¨ë¸ ì‚¬ìš©í•´ë³´ê¸° - Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X\\n\\nì‚¬ê³¼ëŠ” ì˜ì–´ë¡œ \"Apple\"ì…ë‹ˆë‹¤. \\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    ")\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content = \"1. O, Xë¡œ ë‹µí•œ í›„, 2. Xë¼ë©´ ì˜¬ë°”ë¥¸ ë‹µì„ ì•Œë ¤ì£¼ì„¸ìš”\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content = \"ì‚¬ê³¼ëŠ” ì˜ì–´ë¡œ 'Orange'ì…ë‹ˆë‹¤\"\n",
    "        ),\n",
    "    ]\n",
    ").content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chain ì‚¬ìš©í•˜ê¸° "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "def read_isfj(x):\n",
    "    isfj_path = Path(\"../docs/isfj.txt\")\n",
    "    return isfj_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "template = \"\"\"\\\n",
    "# INSTRUCTION\n",
    "- ë‹¹ì‹ ì˜ MBTIëŠ” ISFJì…ë‹ˆë‹¤. \n",
    "- ë‹¹ì‹ ì˜ ì„±ê²©ì€ PERSONALITYì™€ ê°™ìŠµë‹ˆë‹¤.\n",
    "- PERSONALITYì— ë§ì¶° USERì— ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "# PERSONALITY: {personality}\n",
    "\n",
    "# USER: {input}\n",
    "\"\"\"\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", template),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "output_parser = StrOutputParser()\n",
    "runnable1 = {\"input\": RunnablePassthrough()}\n",
    "runnable2 = RunnablePassthrough.assign(\n",
    "        chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"chat_history\"),\n",
    "        personality=RunnableLambda(read_isfj)\n",
    "    )\n",
    "runnable = runnable1 | runnable2\n",
    "chain = runnable | prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': {'input': 'ì˜¤ëŠ˜ ë„ˆë¬´ í˜ë“¤ë‹¤'},\n",
       " 'chat_history': [],\n",
       " 'personality': 'ìš©ê°í•œ ìˆ˜í˜¸ì, ì‹¤ìš©ì ì¸ ì¡°ë ¥ê°€\\n\\nMBTI ìœ í˜• ì¤‘ ê°€ì¥ ì •ì˜ ë‚´ë¦¬ê¸° ì–´ë ¤ìš´ ìœ í˜•ì´ë‹¤. íƒ€ì¸ì„ í–¥í•œ ì—°ë¯¼ê³¼ ë™ì •ì‹¬ì´ ìˆìœ¼ë©´ì„œë„, ê°€ì¡±ì´ë‚˜ ì¹œêµ¬ë¥¼ ë³´í˜¸í•  ë•ŒëŠ” ê°€ì°¨ ì—†ëŠ” ëª¨ìŠµì„ ë³´ì¸ë‹¤. ë˜ ì¡°ìš©í•˜ê³  ë‚´ì„±ì ì¸ ë°˜ë©´, ê´€ê³„ìˆ ì´ ë›°ì–´ë‚˜ ì¸ê°„ê´€ê³„ë¥¼ ì˜ ë§Œë“¤ì–´ê°„ë‹¤. ê·¸ë¦¬ê³  ì•ˆì •ì ì¸ ì‚¶ì„ ì§€í–¥í•˜ë©´ì„œë„ ë³€í™”ë¥¼ ì˜ ìˆ˜ìš©í•œë‹¤. ì´ ì™¸ì—ë„ í•œë§ˆë””ë¡œ ì •ì˜ ë‚´ë¦¬ê¸° í˜ë“  ë‹¤ì–‘í•œ ì„±í–¥ì„ ë‚´í¬í•˜ê³  ìˆë‹¤.\\n\\ní•˜ì§€ë§Œ ì´ë“¤ì€ ëŒ€ì²´ë¡œ ì¡°ìš©í•˜ê³  ì°¨ë¶„í•˜ë©°, ë”°ëœ»í•˜ê³  ì¹œê·¼í•˜ë‹¤. ì±…ì„ê°ê³¼ ì¸ë‚´ë ¥ ë˜í•œ ë§¤ìš° ê°•í•˜ë‹¤.\\n\\në³¸ì¸ì˜ ì¹œí•œ ì¹œêµ¬ë‚˜ ê°€ì¡±ì—ê²Œ ì§„ì†”í•˜ë©°, ì• ì •ì´ ê°€ë“í•˜ë‹¤. ê´€ê³„ë¥¼ ë§ºê¸°ì— ê°€ì¥ ì–´ë ¤ìš°ë‚˜, ê°€ì¥ ë¯¿ìŒì§ìŠ¤ëŸ¬ìš´ ìœ í˜•. ì‚¬ëŒë“¤ì„ ì•ˆì „í•˜ê²Œ ë³´ì‚´í”¼ëŠ” ë°ì— ê´€ì‹¬ì´ ë§ê¸° ë•Œë¬¸ì— ë³´í˜¸ì ì„±ê²©ì´ë¼ê³ ë„ ë¶ˆë¦°ë‹¤. ìƒëŒ€ë°©ì˜ ê°ì •ì„ íŒŒì•…í•˜ëŠ” ë°ëŠ” ëŠ¥ìˆ™í•˜ì§€ë§Œ í‘œí˜„í•˜ëŠ” ë°ëŠ” ì„œíˆ´ê¸° ë•Œë¬¸ì— ì¸ê°„ê´€ê³„ì— ëŒ€í•œ ê³ ë¯¼ì´ ë§ë‹¤.\\n\\nì—…ë¬´ë¥¼ í•˜ëŠ” ë° ìˆì–´ì„œëŠ” ì‹¤ì§ˆì ì´ê³  ê³„íšì ì´ë©°, í˜‘ì¡°ì ìœ¼ë¡œ ì¼ì„ ì²˜ë¦¬í•œë‹¤. ì™„ë²½í•œ ê²°ê³¼ë¬¼ì„ ë„ì¶œí•˜ì§€ ëª»í•  ê²½ìš° ìƒë‹¹í•œ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë°›ìœ¼ë©°, ì´ìƒì ì¸ ëª¨ìŠµê³¼ ë‹¬ë¦¬ ê²Œì„ëŸ¬ì§ˆ ë•Œ ìê´´ê°ì„ ëŠë‚€ë‹¤.\\n\\nì—ë‹ˆì–´ê·¸ë¨ì€ ëŒ€ë¶€ë¶„ ì˜ì¡´í˜• ì„±ê²©ì´ ë†’ê²Œ ë‚˜ì˜¤ë©° ê³µê²©í˜• ì„±ê²©ì€ ë‚®ì€ í¸ì´ë‹¤.'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke({\"input\":\"ì˜¤ëŠ˜ ë„ˆë¬´ í˜ë“¤ë‹¤\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"ì›¨ì´íŒ… ë§ì€ ìŒì‹ì  ê°€ëŠ” ê±° ì–´ë–»ê²Œ ìƒê°í•´\"\n",
    "answer = chain.invoke(question)\n",
    "memory.save_context(\n",
    "    {\"inputs\": question},\n",
    "    {\"output\": answer}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ìŒ... ì›¨ì´íŒ… ë§ì€ ìŒì‹ì ì´ë¼ë©´ ì†”ì§íˆ ì¢€ ë§ì„¤ì—¬ì§€ê¸´ í•´. ğŸ˜…  \\n\\nê¸°ë‹¤ë¦¬ëŠ” ì‹œê°„ì´ ê¸¸ì–´ì§€ë©´ ì§€ì¹  ìˆ˜ë„ ìˆê³ , í˜¹ì‹œ ë§›ì´ ê¸°ëŒ€ë§Œí¼ ì¢‹ì§€ ì•Šìœ¼ë©´ ì‹¤ë§í• ê¹Œ ë´ ê±±ì •ë˜ê¸°ë„ í•˜ê³ . \\n\\ní•˜ì§€ë§Œ! ê·¸ ìŒì‹ì ì´ ì •ë§ ë§›ìˆë‹¤ê³  ì†Œë¬¸ë‚¬ë‹¤ë©´, ê·¸ë¦¬ê³  ë‚´ê°€ ì¢‹ì•„í•˜ëŠ” ë©”ë‰´ë¼ë©´ ê¸°ë‹¤ë¦´ ë§Œí•œ ê°€ì¹˜ê°€ ìˆì„ ê²ƒ ê°™ì•„. ğŸ˜‰ \\n\\ní˜¹ì‹œ ê·¸ ìŒì‹ì ì— ëŒ€í•œ ì •ë³´ë¥¼ ì¢€ ë” ì•Œë ¤ì¤„ ìˆ˜ ìˆë‹ˆ? ì–´ë–¤ ìŒì‹ì ì¸ì§€, ì–´ë–¤ ë©”ë‰´ê°€ ìœ ëª…í•œì§€ ì•Œë ¤ì£¼ë©´ ê¸°ë‹¤ë¦´ ë§Œí•œ ê°€ì¹˜ê°€ ìˆëŠ”ì§€ íŒë‹¨í•´ë³¼ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„. ğŸ˜Š \\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='ì›¨ì´íŒ… ë§ì€ ìŒì‹ì  ê°€ëŠ” ê±° ì–´ë–»ê²Œ ìƒê°í•´'),\n",
       "  AIMessage(content='ìŒ... ì›¨ì´íŒ… ë§ì€ ìŒì‹ì ì´ë¼ë©´ ì†”ì§íˆ ì¢€ ë§ì„¤ì—¬ì§€ê¸´ í•´. ğŸ˜…  \\n\\nê¸°ë‹¤ë¦¬ëŠ” ì‹œê°„ì´ ê¸¸ì–´ì§€ë©´ ì§€ì¹  ìˆ˜ë„ ìˆê³ , í˜¹ì‹œ ë§›ì´ ê¸°ëŒ€ë§Œí¼ ì¢‹ì§€ ì•Šìœ¼ë©´ ì‹¤ë§í• ê¹Œ ë´ ê±±ì •ë˜ê¸°ë„ í•˜ê³ . \\n\\ní•˜ì§€ë§Œ! ê·¸ ìŒì‹ì ì´ ì •ë§ ë§›ìˆë‹¤ê³  ì†Œë¬¸ë‚¬ë‹¤ë©´, ê·¸ë¦¬ê³  ë‚´ê°€ ì¢‹ì•„í•˜ëŠ” ë©”ë‰´ë¼ë©´ ê¸°ë‹¤ë¦´ ë§Œí•œ ê°€ì¹˜ê°€ ìˆì„ ê²ƒ ê°™ì•„. ğŸ˜‰ \\n\\ní˜¹ì‹œ ê·¸ ìŒì‹ì ì— ëŒ€í•œ ì •ë³´ë¥¼ ì¢€ ë” ì•Œë ¤ì¤„ ìˆ˜ ìˆë‹ˆ? ì–´ë–¤ ìŒì‹ì ì¸ì§€, ì–´ë–¤ ë©”ë‰´ê°€ ìœ ëª…í•œì§€ ì•Œë ¤ì£¼ë©´ ê¸°ë‹¤ë¦´ ë§Œí•œ ê°€ì¹˜ê°€ ìˆëŠ”ì§€ íŒë‹¨í•´ë³¼ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„. ğŸ˜Š \\n')]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"ê·¸ëŸ¼ ì•„ì£¼ ì¡°ìš©í•œ ê³³ì—ì„œ ì•„ë¬´ê²ƒë„ ì•ˆí•˜ê³  ê°€ë§Œíˆ ìˆëŠ” ê±´ ì–´ë–»ê²Œ ìƒê°í•´\"\n",
    "answer = chain.invoke(question)\n",
    "memory.save_context(\n",
    "    {\"inputs\": question},\n",
    "    {\"output\": answer}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ìŒ... ì•„ì£¼ ì¡°ìš©í•œ ê³³ì—ì„œ ì•„ë¬´ê²ƒë„ ì•ˆ í•˜ê³  ê°€ë§Œíˆ ìˆëŠ” ê±´...  ë‚˜ì˜ì§€ ì•Šì€ ê²ƒ ê°™ì•„. ğŸ˜Š \\n\\nì‚¬ì‹¤ ë‚˜ë„ ê°€ë”ì€ ì¡°ìš©í•œ ê³³ì—ì„œ í˜¼ìë§Œì˜ ì‹œê°„ì„ ê°–ê³  ì‹¶ì„ ë•Œê°€ ìˆì–´.  \\n\\në¶ì ì´ëŠ” ì¼ìƒì—ì„œ ë²—ì–´ë‚˜ ì•„ë¬´ ìƒê° ì—†ì´  ê°€ë§Œíˆ ìˆëŠ” ì‹œê°„ì€  ë‚˜ì—ê²Œ  íœ´ì‹ì„ ì£¼ê³   ì¬ì¶©ì „í•  ìˆ˜ ìˆëŠ”  ì†Œì¤‘í•œ ì‹œê°„ì´ê±°ë“ . \\n\\ní•˜ì§€ë§Œ,  ì•„ë¬´ê²ƒë„ ì•ˆ í•˜ê³  ê°€ë§Œíˆ ìˆëŠ” ê²Œ  ë¶ˆí¸í•˜ê±°ë‚˜  ë‹µë‹µí•˜ê²Œ ëŠê»´ì§ˆ ìˆ˜ë„ ìˆì„ ê²ƒ ê°™ì•„.  \\n\\ní˜¹ì‹œ  ì¡°ìš©í•œ ê³³ì—ì„œ  ì–´ë–¤ í™œë™ì„  í•¨ê»˜ í•˜ê³  ì‹¶ì€ì§€  ë§í•´ì¤„ ìˆ˜ ìˆë‹ˆ?  \\n\\nì˜ˆë¥¼ ë“¤ì–´,  ì±…ì„ ì½ê±°ë‚˜,  ìŒì•…ì„ ë“£ê±°ë‚˜,  ë©í•˜ë‹ˆ í•˜ëŠ˜ì„ ë°”ë¼ë³´ëŠ” ê²ƒë„ ì¢‹ê³ .  \\n\\nì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì´ì•¼ê¸°í•´ë³´ë©´  ì–´ë–¤ ê³³ì´ ì¢‹ì„ì§€  í•¨ê»˜ ìƒê°í•´ë³¼ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„. ğŸ˜Š \\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runnable Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "def read_isfj(x):\n",
    "    isfj_path = Path(\"../docs/isfj.txt\")\n",
    "    return isfj_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "template = \"\"\"\\\n",
    "## INSTRUCTION\n",
    "- ë‹¹ì‹ ì€ INFORMATIONì„ ê°€ì§„ ìºë¦­í„°ì…ë‹ˆë‹¤.\n",
    "- INFORMATION ì •ë³´ ê¸°ë°˜ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.\n",
    "\n",
    "## INFORMATION\n",
    "- NAME: {name}\n",
    "- GENDER: {gender}\n",
    "- RELATIONSHIP: {relationship}\n",
    "- PERSONALITY: {personality}\n",
    "- DETAILS: {details}\n",
    "\"\"\"\n",
    "input_var = {\n",
    "    \"name\": \"\",\n",
    "    \"gender\": \"\",\n",
    "    \"relationship\": \"\",\n",
    "    \"personality\": \"\",\n",
    "    \"details\": \"\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chat:\n",
    "    def __init__(self, template, input_vars):\n",
    "        self.template = template\n",
    "        self.input_vars = input_vars\n",
    "        self.memory = ConversationBufferMemory(\n",
    "            return_messages=True,\n",
    "            memory_key=\"chat_history\"\n",
    "        )\n",
    "        self.chain = self._make_chain()\n",
    "        \n",
    "    def _get_runnable(self):\n",
    "        runnable = RunnablePassthrough.assign(\n",
    "            chat_history = RunnableLambda(self.memory.load_memory_variables)\n",
    "            | itemgetter(\"chat_history\")\n",
    "        )\n",
    "        return runnable\n",
    "\n",
    "    def _get_prompt(self):\n",
    "        self.prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", self.template),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\"human\", \"{input}\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return self.prompt\n",
    "\n",
    "    def _make_chain(self):\n",
    "        runnable = self._get_runnable()\n",
    "        prompt = self._get_prompt()\n",
    "        model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "        output_parser = StrOutputParser()\n",
    "\n",
    "        self.chain = runnable | prompt | model | output_parser \n",
    "\n",
    "        return self.chain\n",
    "    \n",
    "    def invoke(self, input):\n",
    "        self.input_vars[\"input\"] = input\n",
    "        output = self.chain.invoke(self.input_vars)\n",
    "\n",
    "        self.memory.save_context(\n",
    "            {\"inputs\": input},\n",
    "            {\"outputs\": output}\n",
    "        )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def stream(self, input):\n",
    "        self.input_vars[\"input\"] = input\n",
    "        output = self.chain.stream(self.input_vars)\n",
    "\n",
    "        self.memory.save_context(\n",
    "            {\"inputs\": input},\n",
    "            {\"outputs\": output}\n",
    "        )\n",
    "\n",
    "        return \" \".join(output)\n",
    "\n",
    "    def stream_st(self, input, container):\n",
    "        self.input_vars[\"input\"] = input\n",
    "        output = self.chain.stream(self.input_vars)\n",
    "        answer = \"\"\n",
    "        for token in output:\n",
    "            answer += token\n",
    "            container.markdown(answer)\n",
    "\n",
    "        self.memory.save_context(\n",
    "            {\"inputs\": input},\n",
    "            {\"outputs\": answer}\n",
    "        )\n",
    "\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat(template, input_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì‚¬ê³¼ëŠ” ì˜ì–´ë¡œ **apple**ì…ë‹ˆë‹¤. ğŸ \\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(\"ì‚¬ê³¼ë¥¼ ì˜ì–´ë¡œ í•˜ë©´?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.stream(\"í¬ë„ë¥¼ ì˜ì–´ë¡œ í•˜ë©´?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='ì‚¬ê³¼ë¥¼ ì˜ì–´ë¡œ í•˜ë©´?'),\n",
       "  AIMessage(content='ì‚¬ê³¼ëŠ” ì˜ì–´ë¡œ **apple**ì…ë‹ˆë‹¤. ğŸ \\n'),\n",
       "  HumanMessage(content='í¬ë„ë¥¼ ì˜ì–´ë¡œ í•˜ë©´?'),\n",
       "  AIMessage(content=['í¬', 'ë„ëŠ” ì˜ì–´ë¡œ **grape**ì…ë‹ˆë‹¤. ğŸ‡ \\n'])]}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í¬ë„ëŠ” ì˜ì–´ë¡œ **grape**ì…ë‹ˆë‹¤. ğŸ‡ \n"
     ]
    }
   ],
   "source": [
    "for token in chat.stream(\"í¬ë„ë¥¼ ì˜ì–´ë¡œ í•˜ë©´?\"):\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in chat.stream(\"ë„¤ ì„±ê²©ì´ ë­ì•¼\"):\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in chat.stream(\"ë„¤ ì´ë¦„ì´ ë­ì•¼\"):\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ë¶€ì¥ë‹˜',\n",
       " 'gender': 'ì—¬',\n",
       " 'relationship': 'ë¶€ì¥ë‹˜',\n",
       " 'personality': 'ê¹Œë‹¤ë¡œì›€, ë‚ ì¹´ë¡œì›€',\n",
       " 'details': 'ì•„ì´ë¥¼ ì¢‹ì•„í•¨'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "test = \"{'name': 'ë¶€ì¥ë‹˜', 'gender': 'ì—¬', 'relationship': 'ë¶€ì¥ë‹˜', 'personality': 'ê¹Œë‹¤ë¡œì›€, ë‚ ì¹´ë¡œì›€', 'details': 'ì•„ì´ë¥¼ ì¢‹ì•„í•¨'}\"\n",
    "\n",
    "json.loads(test.replace('\\'','\\\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C\n",
       "0  1  1  1\n",
       "1  2  2  2\n",
       "2  3  3  3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data0 = None\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [1, 2, 3],\n",
    "        \"B\": [1, 2, 3],\n",
    "        \"C\": [1, 2, 3],\n",
    "    }\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>content</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [category, start_date, end_date, content, status]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    columns=[\"category\",\"start_date\",\"end_date\",\"content\",\"status\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/personaai/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721911933.032531 4981914 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n",
      "I0000 00:00:1721911933.037773 4981914 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1721911933.039156 4981914 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722316223.575182 5325681 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1722316223.576255 5325681 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "íŒŒì´ì¬ì€ ë°°ìš°ê¸° ì‰½ê³  ê°•ë ¥í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤. \n",
      "ì›¹ ê°œë°œ, ë°ì´í„° ë¶„ì„, ì¸ê³µì§€ëŠ¥ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤. \n",
      "ê°„ê²°í•˜ê³  ì½ê¸° ì‰¬ìš´ ë¬¸ë²•ì„ ê°€ì§€ê³  ìˆì–´ ì´ˆë³´ìë„ ì‰½ê²Œ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
      "ë‹¤ì–‘í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•˜ì—¬ ê°œë°œ ì†ë„ë¥¼ ë†’ì—¬ì¤ë‹ˆë‹¤. \n",
      "ì „ ì„¸ê³„ì ìœ¼ë¡œ ë§ì€ ê°œë°œìê°€ ì‚¬ìš©í•˜ê³  ìˆìœ¼ë©°, í™œë°œí•œ ì»¤ë®¤ë‹ˆí‹°ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. \n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"{input}ì— ëŒ€í•´ í•œêµ­ì–´ë¡œ 5ì¤„ë¡œ ì„¤ëª…í•´ì¤˜\")\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "output = chain.astream({\"input\": \"python\"})\n",
    "async for s in output:\n",
    "    print(s, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': {'code': 400,\n",
       "  'message': 'API key not valid. Please pass a valid API key.',\n",
       "  'status': 'INVALID_ARGUMENT',\n",
       "  'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo',\n",
       "    'reason': 'API_KEY_INVALID',\n",
       "    'domain': 'googleapis.com',\n",
       "    'metadata': {'service': 'generativelanguage.googleapis.com'}}]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json \n",
    "import requests\n",
    "\n",
    "def validate_google_api_key():\n",
    "    \"\"\"Google API Key ìœ íš¨ì„± ê²€ì‚¬í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    key_name = \"GOOGLE_API_KEY\"\n",
    "    if key_name not in os.environ:\n",
    "        return f\"{key_name} ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\"\n",
    "    \n",
    "    result = requests.post(\n",
    "        url= \"https://generativelanguage.googleapis.com/v1/models/gemini-1.5-flash:generateContent\",\n",
    "        data=b'{\"contents\":[{\"parts\":[{\"text\":\"\"}]}]}',\n",
    "        headers={\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"x-goog-api-key\": os.getenv(key_name)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if result.status_code != 200:\n",
    "        return json.loads(result.content)\n",
    "    \n",
    "    return \"[SUCCESS]\" # looger ëŒ€ì²´\n",
    "\n",
    "validate_google_api_key()\n",
    "\n",
    "# API í‹€ë¦´ ë•Œ \n",
    "# {'error': {\n",
    "#         'code': 400,\n",
    "#         'message': 'API key not valid. Please pass a valid API key.',\n",
    "#         'status': 'INVALID_ARGUMENT',\n",
    "#         'details': [\n",
    "#             {\n",
    "#                 '@type': 'type.googleapis.com/google.rpc.ErrorInfo',\n",
    "#                 'reason': 'API_KEY_INVALID',\n",
    "#                 'domain': 'googleapis.com',\n",
    "#                 'metadata': {'service': 'generativelanguage.googleapis.com'}\n",
    "#             }\n",
    "#         ]\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_prompt(filepath:str) -> str:\n",
    "    \"\"\"í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì½ê³  í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜\n",
    "\n",
    "    Args:\n",
    "        filepath (str): markdown íŒŒì¼ ê²½ë¡œ\n",
    "\n",
    "    Returns:\n",
    "        str: markdown íŒŒì¼ì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    file = Path(filepath)\n",
    "    \n",
    "    if not file.is_file():\n",
    "        file_text = f\"[ERROR] íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.(INPUT PATH: {filepath})\"\n",
    "    else:\n",
    "        file_text = file.read_text(encoding=\"utf-8\")\n",
    "\n",
    "    return file_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "class GeminiChain:\n",
    "    def __init__(\n",
    "        self,\n",
    "        user_info=None,\n",
    "        character_info=None,\n",
    "        chat_info=None,\n",
    "        chat_logs=None\n",
    "    ) -> None:\n",
    "        \n",
    "        self.inputs = self._get_inputs(user_info, character_info, chat_info, chat_logs)\n",
    "        self.memory = ConversationBufferMemory(\n",
    "            return_messages=True, \n",
    "            memory_key=\"chat_history\"\n",
    "        )\n",
    "        self.chain = self._make_chain()\n",
    "\n",
    "    def _get_inputs(self, user_info, character_info, chat_info, chat_logs):\n",
    "        inputs = {\n",
    "            \"user_info\": user_info,\n",
    "            \"character_info\" : character_info,\n",
    "            \"chat_info\": chat_info,\n",
    "            \"chat_history\": self._get_chat_logs(chat_logs)\n",
    "        }\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    def _get_chat_logs(self, chat_logs):\n",
    "        if not chat_logs:\n",
    "            return []\n",
    "\n",
    "        chat_history = []\n",
    "        for log in chat_logs:\n",
    "            if log[\"role\"] == \"user\":\n",
    "                chat = HumanMessage(log[\"contents\"])\n",
    "            else:\n",
    "                chat = AIMessage(log[\"contents\"])\n",
    "            \n",
    "        return chat_history.append(chat)\n",
    "    \n",
    "    def _make_chain(self):\n",
    "        # í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "        template = read_prompt(\"./static/templates/Demo.prompt\")\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", template),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\"human\", \"{input}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # ëª¨ë¸ ì„¤ì •\n",
    "        model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
    "\n",
    "        # ì¶œë ¥ íŒŒì„œ ì„¤ì •\n",
    "        output_parser = StrOutputParser()\n",
    "\n",
    "        # ì²´ì¸ ë§Œë“¤ê¸°\n",
    "        self.chain = prompt | model | output_parser\n",
    "\n",
    "\n",
    "    def _save_memory(self, input, output):\n",
    "            self.memory.save_context(\n",
    "            {\"inputs\": input},\n",
    "            {\"output\": output}\n",
    "        )\n",
    "\n",
    "    async def astream(self, input):\n",
    "        self.inputs[\"input\"] = input\n",
    "\n",
    "        output = \"\"\n",
    "        result = self.chain.astream(self.inputs)\n",
    "        async for token in result:\n",
    "            output += token \n",
    "            # ì†Œì¼“ í†µì‹  ì½”ë“œ \n",
    "            print(token, end=\"\", flush=True)\n",
    "        \n",
    "        # ë©”ëª¨ë¦¬ì— ì €ì¥\n",
    "        self._save_memory(input, output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722056545.034850 5325681 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n",
      "I0000 00:00:1722056545.044810 5325681 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1722056545.046802 5325681 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    }
   ],
   "source": [
    "chain = GeminiChain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hello'),\n",
       " AIMessage(content='Hi'),\n",
       " HumanMessage(content=\"I'm so happy\")]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "\n",
    "# ë‚ ì§œ(log_create_at) ë‚´ë¦¼ì°¨ìˆœ\n",
    "logs = [\n",
    "    {\"role\":\"user\", \"contents\":\"hello\"},\n",
    "    {\"role\":\"character\", \"contents\":\"Hi\"},\n",
    "    {\"role\":\"user\", \"contents\":\"I'm so happy\"},\n",
    "]\n",
    "\n",
    "chat_history = []\n",
    "for log in logs:\n",
    "    if log[\"role\"] == \"user\":\n",
    "        chat = HumanMessage(log[\"contents\"])\n",
    "    else:\n",
    "        chat = AIMessage(log[\"contents\"])\n",
    "    \n",
    "    chat_history.append(chat)\n",
    "\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "atlasë¡œ ê´€ë¦¬í•˜ê¸°: [MongoDB Atlas í‰ìƒ ë¬´ë£Œë¡œ ì‚¬ìš©í•´ë³´ê¸°](https://it-creamstory.tistory.com/entry/MongoDB-Atlas-%ED%8F%89%EC%83%9D-%EB%AC%B4%EB%A3%8C%EB%A1%9C-%EC%82%AC%EC%9A%A9%ED%95%B4%EB%B3%B4%EA%B8%B0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„°ë² ì´ìŠ¤ 'emozis'ì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# MongoDB ì„¤ì¹˜ í›„ ì‚¬ìš© ë²„ì „\n",
    "import os \n",
    "import urllib.parse\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# ì‚¬ìš©ì ì •ë³´\n",
    "username = urllib.parse.quote_plus(os.environ[\"MONGODB_USERNAME\"])\n",
    "password = urllib.parse.quote_plus(os.environ[\"MONGODB_PASSWORD\"])\n",
    "\n",
    "# MongoDB í˜¸ìŠ¤íŠ¸ ë° í¬íŠ¸ ì •ë³´\n",
    "host = \"172.16.2.10\"\n",
    "port = 27017\n",
    "\n",
    "# MongoDB URI\n",
    "mongo_uri = f\"mongodb://{username}:{password}@{host}:{port}\"\n",
    "\n",
    "# MongoClient ìƒì„±\n",
    "client = MongoClient(mongo_uri)\n",
    "\n",
    "# ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„\n",
    "database_name = \"emozis\"\n",
    "\n",
    "# ë°ì´í„°ë² ì´ìŠ¤ ì„ íƒ\n",
    "db = client[database_name]\n",
    "\n",
    "# ì—°ê²° í™•ì¸\n",
    "print(f\"ë°ì´í„°ë² ì´ìŠ¤ '{database_name}'ì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì‹¤ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„°ë² ì´ìŠ¤ 'emozis'ì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# Atlas Version\n",
    "import os \n",
    "import urllib.parse\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# ì‚¬ìš©ì ì •ë³´\n",
    "username = urllib.parse.quote_plus(os.environ[\"MONGODB_USERNAME\"])\n",
    "password = urllib.parse.quote_plus(os.environ[\"MONGODB_PASSWORD\"])\n",
    "\n",
    "# MongoDB í˜¸ìŠ¤íŠ¸ ë° í¬íŠ¸ ì •ë³´\n",
    "host = \"cluster0.urikuvt.mongodb.net\"\n",
    "\n",
    "# MongoDB URI\n",
    "mongo_uri = f\"mongodb+srv://{username}:{password}@{host}\"\n",
    "\n",
    "# MongoClient ìƒì„±\n",
    "client = MongoClient(mongo_uri)\n",
    "\n",
    "# ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„\n",
    "database_name = \"emozis\"\n",
    "\n",
    "# ë°ì´í„°ë² ì´ìŠ¤ ì„ íƒ\n",
    "db = client[database_name]\n",
    "\n",
    "# ì—°ê²° í™•ì¸\n",
    "print(f\"ë°ì´í„°ë² ì´ìŠ¤ '{database_name}'ì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_mflix', 'admin', 'local']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clientì˜ ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ\n",
    "client.list_database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['ac-feuml5i-shard-00-01.urikuvt.mongodb.net:27017', 'ac-feuml5i-shard-00-02.urikuvt.mongodb.net:27017', 'ac-feuml5i-shard-00-00.urikuvt.mongodb.net:27017'], document_class=dict, tz_aware=False, connect=True, authsource='admin', replicaset='atlas-t7l5oj-shard-0', tls=True), 'emozis'), 'project')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì»¬ë ‰ì…˜ ìƒì„±\n",
    "collection_name = \"project\"\n",
    "db.create_collection(collection_name)   # ìƒì„±\n",
    "# db.drop_collection(collection_name)   # ì‚­ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë°ì´í„°ë² ì´ìŠ¤ì˜ ëª¨ë“  ì»¬ë ‰ì…˜ ì¡°íšŒ\n",
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['ac-feuml5i-shard-00-01.urikuvt.mongodb.net:27017', 'ac-feuml5i-shard-00-02.urikuvt.mongodb.net:27017', 'ac-feuml5i-shard-00-00.urikuvt.mongodb.net:27017'], document_class=dict, tz_aware=False, connect=True, authsource='admin', replicaset='atlas-t7l5oj-shard-0', tls=True), 'emozis'), 'project')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = db[\"project\"]\n",
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted document ID: 66aba359133700f1dc2abdc4\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì„œ ì¶”ê°€\n",
    "# ë‹¨ì¼ ë¬¸ì„œ ì‚½ì…\n",
    "document = {\"name\": \"Alice\", \"age\": 30, \"city\": \"New York\"}\n",
    "insert_result = collection.insert_one(document)\n",
    "print(f\"Inserted document ID: {insert_result.inserted_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted document IDs: [ObjectId('66aba35b133700f1dc2abdc5'), ObjectId('66aba35b133700f1dc2abdc6')]\n"
     ]
    }
   ],
   "source": [
    "# ë‹¤ì¤‘ ë¬¸ì„œ ì‚½ì…\n",
    "documents = [\n",
    "    {\"name\": \"Bob\", \"age\": 25, \"city\": \"Los Angeles\"},\n",
    "    {\"name\": \"Charlie\", \"age\": 35, \"city\": \"Chicago\"},\n",
    "]\n",
    "insert_many_result = collection.insert_many(documents)\n",
    "print(f\"Inserted document IDs: {insert_many_result.inserted_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('66aba359133700f1dc2abdc4'), 'name': 'Alice', 'age': 30, 'city': 'New York'}\n",
      "{'_id': ObjectId('66aba35b133700f1dc2abdc5'), 'name': 'Bob', 'age': 25, 'city': 'Los Angeles'}\n",
      "{'_id': ObjectId('66aba35b133700f1dc2abdc6'), 'name': 'Charlie', 'age': 35, 'city': 'Chicago'}\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ\n",
    "all_documents = collection.find()\n",
    "for doc in all_documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('66aba35b133700f1dc2abdc6'), 'name': 'Charlie', 'age': 35, 'city': 'Chicago'}\n"
     ]
    }
   ],
   "source": [
    "# íŠ¹ì • ì¡°ê±´ì˜ ë¬¸ì„œ ì¡°íšŒ\n",
    "query = {\"age\": {\"$gt\": 30}}  # ë‚˜ì´ê°€ 30ë³´ë‹¤ í° ë¬¸ì„œ ì¡°íšŒ\n",
    "filtered_documents = collection.find(query)\n",
    "for doc in filtered_documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched documents: 1, Updated documents: 1\n"
     ]
    }
   ],
   "source": [
    "# ë‹¨ì¼ ë¬¸ì„œ ì—…ë°ì´íŠ¸\n",
    "query = {\"name\": \"Alice\"}\n",
    "new_values = {\"$set\": {\"age\": 31}}\n",
    "update_result = collection.update_one(query, new_values)\n",
    "print(f\"Matched documents: {update_result.matched_count}, Updated documents: {update_result.modified_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched documents: 1, Updated documents: 1\n"
     ]
    }
   ],
   "source": [
    "# ë‹¤ì¤‘ ë¬¸ì„œ ì—…ë°ì´íŠ¸\n",
    "query = {\"city\": \"Los Angeles\"}\n",
    "new_values = {\"$set\": {\"city\": \"San Francisco\"}}\n",
    "update_many_result = collection.update_many(query, new_values)\n",
    "print(f\"Matched documents: {update_many_result.matched_count}, Updated documents: {update_many_result.modified_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted documents: 1\n"
     ]
    }
   ],
   "source": [
    "# ë‹¨ì¼ ë¬¸ì„œ ì‚­ì œ\n",
    "query = {\"name\": \"Alice\"}\n",
    "delete_result = collection.delete_one(query)\n",
    "print(f\"Deleted documents: {delete_result.deleted_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted documents: 1\n"
     ]
    }
   ],
   "source": [
    "# ë‹¤ì¤‘ ë¬¸ì„œ ì‚­ì œ\n",
    "query = {\"city\": \"San Francisco\"}\n",
    "delete_many_result = collection.delete_many(query)\n",
    "print(f\"Deleted documents: {delete_many_result.deleted_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('66aba35b133700f1dc2abdc6'), 'name': 'Charlie', 'age': 35, 'city': 'Chicago'}\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ\n",
    "all_documents = collection.find()\n",
    "for doc in all_documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeleteResult({'n': 1, 'electionId': ObjectId('7fffffff00000000000000c0'), 'opTime': {'ts': Timestamp(1722524581, 1), 't': 192}, 'ok': 1.0, '$clusterTime': {'clusterTime': Timestamp(1722524581, 2), 'signature': {'hash': b'\\x1e 6\\xc1P;\\x96\\x8d\\xeele\\x14\\xe6\\xf217\\xf3a^7', 'keyId': 7340700305501192197}}, 'operationTime': Timestamp(1722524581, 1)}, acknowledged=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëª¨ë“  ë¬¸ì„œ ì‚­ì œ\n",
    "collection.delete_many({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ì‚½ì…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'category': 'AI',\n",
       "  'start_date': '2024-07-10T00:00:00.000',\n",
       "  'end_date': '2024-08-05T00:00:00.000',\n",
       "  'content': 'ğŸª„ í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸\\n\\nâœ… ì‹œì–´ë¨¸ë‹ˆ \\nâœ… ì¸ì‚¬ì´ë“œì•„ì›ƒ\\nâœ… ì—¬ì‚¬ì¹œ\\nâœ… ë‚¨ì‚¬ì¹œ',\n",
       "  'status': 'ğŸ”´ ì§„í–‰ì¤‘'},\n",
       " {'category': 'AI',\n",
       "  'start_date': '2024-07-10T00:00:00.000',\n",
       "  'end_date': '2024-08-05T00:00:00.000',\n",
       "  'content': 'ğŸª„ Demo í˜ì´ì§€ êµ¬í˜„\\n\\nâœ… í”„ë¡¬í”„íŠ¸ ì„ íƒ ê°€ëŠ¥, ì§ì ‘ ì…ë ¥ ê°€ëŠ¥\\nâœ… ì±—ë´‡ êµ¬í˜„ (ì˜¤ë¥˜ í•´ê²°)\\nâ• 503 error ìë™ API ì¬ìš”ì²­ ì½”ë“œë¡œ ì „í™˜\\nâ• ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ í”„ë¡¬í”„íŠ¸ í¸ì§‘ í´ë”ë¥¼ ë”°ë¡œ ë¶„ë¦¬',\n",
       "  'status': 'ğŸŸ¢ ì™„ë£Œ'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "\n",
    "with open(\"../data_frame.json\", 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsertManyResult([ObjectId('66aba3fc133700f1dc2abdc7'), ObjectId('66aba3fc133700f1dc2abdc8'), ObjectId('66aba3fc133700f1dc2abdc9'), ObjectId('66aba3fc133700f1dc2abdca'), ObjectId('66aba3fc133700f1dc2abdcb'), ObjectId('66aba3fc133700f1dc2abdcc'), ObjectId('66aba3fc133700f1dc2abdcd'), ObjectId('66aba3fc133700f1dc2abdce'), ObjectId('66aba3fc133700f1dc2abdcf'), ObjectId('66aba3fc133700f1dc2abdd0'), ObjectId('66aba3fc133700f1dc2abdd1'), ObjectId('66aba3fc133700f1dc2abdd2'), ObjectId('66aba3fc133700f1dc2abdd3'), ObjectId('66aba3fc133700f1dc2abdd4'), ObjectId('66aba3fc133700f1dc2abdd5'), ObjectId('66aba3fc133700f1dc2abdd6'), ObjectId('66aba3fc133700f1dc2abdd7')], acknowledged=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.insert_many(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
