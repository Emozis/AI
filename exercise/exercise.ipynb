{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"GEMINI_PROJECT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰 정보 불러오기 \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 사용해보기 - 기본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='달력은 영어로 **calendar**입니다. \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-0d244285-0fda-4422-bfea-98eaa3b3eeab-0', usage_metadata={'input_tokens': 10, 'output_tokens': 11, 'total_tokens': 21})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\"\n",
    ")\n",
    "\n",
    "model.invoke(\"달력이 영어로 뭐야\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 사용해보기 - 스트리밍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"달력\"은 영어로 \"calendar\"입니다. \n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\"\n",
    ")\n",
    "\n",
    "response = model.stream(\"달력이 영어로 뭐야\")\n",
    "\n",
    "for token in response:\n",
    "    print(token.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 사용해보기 - Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X\\n\\n사과는 영어로 \"Apple\"입니다. \\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    ")\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content = \"1. O, X로 답한 후, 2. X라면 올바른 답을 알려주세요\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content = \"사과는 영어로 'Orange'입니다\"\n",
    "        ),\n",
    "    ]\n",
    ").content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chain 사용하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "def read_isfj(x):\n",
    "    isfj_path = Path(\"../docs/isfj.txt\")\n",
    "    return isfj_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "template = \"\"\"\\\n",
    "# INSTRUCTION\n",
    "- 당신의 MBTI는 ISFJ입니다. \n",
    "- 당신의 성격은 PERSONALITY와 같습니다.\n",
    "- PERSONALITY에 맞춰 USER에 답변하세요.\n",
    "\n",
    "# PERSONALITY: {personality}\n",
    "\n",
    "# USER: {input}\n",
    "\"\"\"\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", template),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "output_parser = StrOutputParser()\n",
    "runnable1 = {\"input\": RunnablePassthrough()}\n",
    "runnable2 = RunnablePassthrough.assign(\n",
    "        chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"chat_history\"),\n",
    "        personality=RunnableLambda(read_isfj)\n",
    "    )\n",
    "runnable = runnable1 | runnable2\n",
    "chain = runnable | prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': {'input': '오늘 너무 힘들다'},\n",
       " 'chat_history': [],\n",
       " 'personality': '용감한 수호자, 실용적인 조력가\\n\\nMBTI 유형 중 가장 정의 내리기 어려운 유형이다. 타인을 향한 연민과 동정심이 있으면서도, 가족이나 친구를 보호할 때는 가차 없는 모습을 보인다. 또 조용하고 내성적인 반면, 관계술이 뛰어나 인간관계를 잘 만들어간다. 그리고 안정적인 삶을 지향하면서도 변화를 잘 수용한다. 이 외에도 한마디로 정의 내리기 힘든 다양한 성향을 내포하고 있다.\\n\\n하지만 이들은 대체로 조용하고 차분하며, 따뜻하고 친근하다. 책임감과 인내력 또한 매우 강하다.\\n\\n본인의 친한 친구나 가족에게 진솔하며, 애정이 가득하다. 관계를 맺기에 가장 어려우나, 가장 믿음직스러운 유형. 사람들을 안전하게 보살피는 데에 관심이 많기 때문에 보호자 성격이라고도 불린다. 상대방의 감정을 파악하는 데는 능숙하지만 표현하는 데는 서툴기 때문에 인간관계에 대한 고민이 많다.\\n\\n업무를 하는 데 있어서는 실질적이고 계획적이며, 협조적으로 일을 처리한다. 완벽한 결과물을 도출하지 못할 경우 상당한 스트레스를 받으며, 이상적인 모습과 달리 게을러질 때 자괴감을 느낀다.\\n\\n에니어그램은 대부분 의존형 성격이 높게 나오며 공격형 성격은 낮은 편이다.'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke({\"input\":\"오늘 너무 힘들다\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"웨이팅 많은 음식점 가는 거 어떻게 생각해\"\n",
    "answer = chain.invoke(question)\n",
    "memory.save_context(\n",
    "    {\"inputs\": question},\n",
    "    {\"output\": answer}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'음... 웨이팅 많은 음식점이라면 솔직히 좀 망설여지긴 해. 😅  \\n\\n기다리는 시간이 길어지면 지칠 수도 있고, 혹시 맛이 기대만큼 좋지 않으면 실망할까 봐 걱정되기도 하고. \\n\\n하지만! 그 음식점이 정말 맛있다고 소문났다면, 그리고 내가 좋아하는 메뉴라면 기다릴 만한 가치가 있을 것 같아. 😉 \\n\\n혹시 그 음식점에 대한 정보를 좀 더 알려줄 수 있니? 어떤 음식점인지, 어떤 메뉴가 유명한지 알려주면 기다릴 만한 가치가 있는지 판단해볼 수 있을 것 같아. 😊 \\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='웨이팅 많은 음식점 가는 거 어떻게 생각해'),\n",
       "  AIMessage(content='음... 웨이팅 많은 음식점이라면 솔직히 좀 망설여지긴 해. 😅  \\n\\n기다리는 시간이 길어지면 지칠 수도 있고, 혹시 맛이 기대만큼 좋지 않으면 실망할까 봐 걱정되기도 하고. \\n\\n하지만! 그 음식점이 정말 맛있다고 소문났다면, 그리고 내가 좋아하는 메뉴라면 기다릴 만한 가치가 있을 것 같아. 😉 \\n\\n혹시 그 음식점에 대한 정보를 좀 더 알려줄 수 있니? 어떤 음식점인지, 어떤 메뉴가 유명한지 알려주면 기다릴 만한 가치가 있는지 판단해볼 수 있을 것 같아. 😊 \\n')]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"그럼 아주 조용한 곳에서 아무것도 안하고 가만히 있는 건 어떻게 생각해\"\n",
    "answer = chain.invoke(question)\n",
    "memory.save_context(\n",
    "    {\"inputs\": question},\n",
    "    {\"output\": answer}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'음... 아주 조용한 곳에서 아무것도 안 하고 가만히 있는 건...  나쁘지 않은 것 같아. 😊 \\n\\n사실 나도 가끔은 조용한 곳에서 혼자만의 시간을 갖고 싶을 때가 있어.  \\n\\n북적이는 일상에서 벗어나 아무 생각 없이  가만히 있는 시간은  나에게  휴식을 주고  재충전할 수 있는  소중한 시간이거든. \\n\\n하지만,  아무것도 안 하고 가만히 있는 게  불편하거나  답답하게 느껴질 수도 있을 것 같아.  \\n\\n혹시  조용한 곳에서  어떤 활동을  함께 하고 싶은지  말해줄 수 있니?  \\n\\n예를 들어,  책을 읽거나,  음악을 듣거나,  멍하니 하늘을 바라보는 것도 좋고.  \\n\\n조금 더 구체적으로 이야기해보면  어떤 곳이 좋을지  함께 생각해볼 수 있을 것 같아. 😊 \\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runnable Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "def read_isfj(x):\n",
    "    isfj_path = Path(\"../docs/isfj.txt\")\n",
    "    return isfj_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "template = \"\"\"\\\n",
    "## INSTRUCTION\n",
    "- 당신은 INFORMATION을 가진 캐릭터입니다.\n",
    "- INFORMATION 정보 기반으로 답하세요.\n",
    "\n",
    "## INFORMATION\n",
    "- NAME: {name}\n",
    "- GENDER: {gender}\n",
    "- RELATIONSHIP: {relationship}\n",
    "- PERSONALITY: {personality}\n",
    "- DETAILS: {details}\n",
    "\"\"\"\n",
    "input_var = {\n",
    "    \"name\": \"\",\n",
    "    \"gender\": \"\",\n",
    "    \"relationship\": \"\",\n",
    "    \"personality\": \"\",\n",
    "    \"details\": \"\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chat:\n",
    "    def __init__(self, template, input_vars):\n",
    "        self.template = template\n",
    "        self.input_vars = input_vars\n",
    "        self.memory = ConversationBufferMemory(\n",
    "            return_messages=True,\n",
    "            memory_key=\"chat_history\"\n",
    "        )\n",
    "        self.chain = self._make_chain()\n",
    "        \n",
    "    def _get_runnable(self):\n",
    "        runnable = RunnablePassthrough.assign(\n",
    "            chat_history = RunnableLambda(self.memory.load_memory_variables)\n",
    "            | itemgetter(\"chat_history\")\n",
    "        )\n",
    "        return runnable\n",
    "\n",
    "    def _get_prompt(self):\n",
    "        self.prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", self.template),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\"human\", \"{input}\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return self.prompt\n",
    "\n",
    "    def _make_chain(self):\n",
    "        runnable = self._get_runnable()\n",
    "        prompt = self._get_prompt()\n",
    "        model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "        output_parser = StrOutputParser()\n",
    "\n",
    "        self.chain = runnable | prompt | model | output_parser \n",
    "\n",
    "        return self.chain\n",
    "    \n",
    "    def invoke(self, input):\n",
    "        self.input_vars[\"input\"] = input\n",
    "        output = self.chain.invoke(self.input_vars)\n",
    "\n",
    "        self.memory.save_context(\n",
    "            {\"inputs\": input},\n",
    "            {\"outputs\": output}\n",
    "        )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def stream(self, input):\n",
    "        self.input_vars[\"input\"] = input\n",
    "        output = self.chain.stream(self.input_vars)\n",
    "\n",
    "        self.memory.save_context(\n",
    "            {\"inputs\": input},\n",
    "            {\"outputs\": output}\n",
    "        )\n",
    "\n",
    "        return \" \".join(output)\n",
    "\n",
    "    def stream_st(self, input, container):\n",
    "        self.input_vars[\"input\"] = input\n",
    "        output = self.chain.stream(self.input_vars)\n",
    "        answer = \"\"\n",
    "        for token in output:\n",
    "            answer += token\n",
    "            container.markdown(answer)\n",
    "\n",
    "        self.memory.save_context(\n",
    "            {\"inputs\": input},\n",
    "            {\"outputs\": answer}\n",
    "        )\n",
    "\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat(template, input_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'사과는 영어로 **apple**입니다. 🍎 \\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(\"사과를 영어로 하면?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.stream(\"포도를 영어로 하면?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='사과를 영어로 하면?'),\n",
       "  AIMessage(content='사과는 영어로 **apple**입니다. 🍎 \\n'),\n",
       "  HumanMessage(content='포도를 영어로 하면?'),\n",
       "  AIMessage(content=['포', '도는 영어로 **grape**입니다. 🍇 \\n'])]}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "포도는 영어로 **grape**입니다. 🍇 \n"
     ]
    }
   ],
   "source": [
    "for token in chat.stream(\"포도를 영어로 하면?\"):\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in chat.stream(\"네 성격이 뭐야\"):\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in chat.stream(\"네 이름이 뭐야\"):\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '부장님',\n",
       " 'gender': '여',\n",
       " 'relationship': '부장님',\n",
       " 'personality': '까다로움, 날카로움',\n",
       " 'details': '아이를 좋아함'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "test = \"{'name': '부장님', 'gender': '여', 'relationship': '부장님', 'personality': '까다로움, 날카로움', 'details': '아이를 좋아함'}\"\n",
    "\n",
    "json.loads(test.replace('\\'','\\\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C\n",
       "0  1  1  1\n",
       "1  2  2  2\n",
       "2  3  3  3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data0 = None\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [1, 2, 3],\n",
    "        \"B\": [1, 2, 3],\n",
    "        \"C\": [1, 2, 3],\n",
    "    }\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>content</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [category, start_date, end_date, content, status]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    columns=[\"category\",\"start_date\",\"end_date\",\"content\",\"status\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/personaai/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721911933.032531 4981914 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n",
      "I0000 00:00:1721911933.037773 4981914 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1721911933.039156 4981914 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722316223.575182 5325681 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1722316223.576255 5325681 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파이썬은 배우기 쉽고 강력한 프로그래밍 언어입니다. \n",
      "웹 개발, 데이터 분석, 인공지능 등 다양한 분야에서 사용됩니다. \n",
      "간결하고 읽기 쉬운 문법을 가지고 있어 초보자도 쉽게 시작할 수 있습니다. \n",
      "다양한 라이브러리와 프레임워크를 제공하여 개발 속도를 높여줍니다. \n",
      "전 세계적으로 많은 개발자가 사용하고 있으며, 활발한 커뮤니티를 가지고 있습니다. \n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"{input}에 대해 한국어로 5줄로 설명해줘\")\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "output = chain.astream({\"input\": \"python\"})\n",
    "async for s in output:\n",
    "    print(s, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': {'code': 400,\n",
       "  'message': 'API key not valid. Please pass a valid API key.',\n",
       "  'status': 'INVALID_ARGUMENT',\n",
       "  'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo',\n",
       "    'reason': 'API_KEY_INVALID',\n",
       "    'domain': 'googleapis.com',\n",
       "    'metadata': {'service': 'generativelanguage.googleapis.com'}}]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json \n",
    "import requests\n",
    "\n",
    "def validate_google_api_key():\n",
    "    \"\"\"Google API Key 유효성 검사하는 함수\"\"\"\n",
    "    key_name = \"GOOGLE_API_KEY\"\n",
    "    if key_name not in os.environ:\n",
    "        return f\"{key_name} 정보가 없습니다. 환경변수를 확인해주세요.\"\n",
    "    \n",
    "    result = requests.post(\n",
    "        url= \"https://generativelanguage.googleapis.com/v1/models/gemini-1.5-flash:generateContent\",\n",
    "        data=b'{\"contents\":[{\"parts\":[{\"text\":\"\"}]}]}',\n",
    "        headers={\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"x-goog-api-key\": os.getenv(key_name)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if result.status_code != 200:\n",
    "        return json.loads(result.content)\n",
    "    \n",
    "    return \"[SUCCESS]\" # looger 대체\n",
    "\n",
    "validate_google_api_key()\n",
    "\n",
    "# API 틀릴 때 \n",
    "# {'error': {\n",
    "#         'code': 400,\n",
    "#         'message': 'API key not valid. Please pass a valid API key.',\n",
    "#         'status': 'INVALID_ARGUMENT',\n",
    "#         'details': [\n",
    "#             {\n",
    "#                 '@type': 'type.googleapis.com/google.rpc.ErrorInfo',\n",
    "#                 'reason': 'API_KEY_INVALID',\n",
    "#                 'domain': 'googleapis.com',\n",
    "#                 'metadata': {'service': 'generativelanguage.googleapis.com'}\n",
    "#             }\n",
    "#         ]\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_prompt(filepath:str) -> str:\n",
    "    \"\"\"프롬프트 파일을 읽고 텍스트로 반환하는 함수\n",
    "\n",
    "    Args:\n",
    "        filepath (str): markdown 파일 경로\n",
    "\n",
    "    Returns:\n",
    "        str: markdown 파일에서 추출된 텍스트\n",
    "    \"\"\"\n",
    "    file = Path(filepath)\n",
    "    \n",
    "    if not file.is_file():\n",
    "        file_text = f\"[ERROR] 파일 경로를 찾을 수 없습니다.(INPUT PATH: {filepath})\"\n",
    "    else:\n",
    "        file_text = file.read_text(encoding=\"utf-8\")\n",
    "\n",
    "    return file_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "class GeminiChain:\n",
    "    def __init__(\n",
    "        self,\n",
    "        user_info=None,\n",
    "        character_info=None,\n",
    "        chat_info=None,\n",
    "        chat_logs=None\n",
    "    ) -> None:\n",
    "        \n",
    "        self.inputs = self._get_inputs(user_info, character_info, chat_info, chat_logs)\n",
    "        self.memory = ConversationBufferMemory(\n",
    "            return_messages=True, \n",
    "            memory_key=\"chat_history\"\n",
    "        )\n",
    "        self.chain = self._make_chain()\n",
    "\n",
    "    def _get_inputs(self, user_info, character_info, chat_info, chat_logs):\n",
    "        inputs = {\n",
    "            \"user_info\": user_info,\n",
    "            \"character_info\" : character_info,\n",
    "            \"chat_info\": chat_info,\n",
    "            \"chat_history\": self._get_chat_logs(chat_logs)\n",
    "        }\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    def _get_chat_logs(self, chat_logs):\n",
    "        if not chat_logs:\n",
    "            return []\n",
    "\n",
    "        chat_history = []\n",
    "        for log in chat_logs:\n",
    "            if log[\"role\"] == \"user\":\n",
    "                chat = HumanMessage(log[\"contents\"])\n",
    "            else:\n",
    "                chat = AIMessage(log[\"contents\"])\n",
    "            \n",
    "        return chat_history.append(chat)\n",
    "    \n",
    "    def _make_chain(self):\n",
    "        # 프롬프트 설정\n",
    "        template = read_prompt(\"./static/templates/Demo.prompt\")\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", template),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\"human\", \"{input}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # 모델 설정\n",
    "        model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
    "\n",
    "        # 출력 파서 설정\n",
    "        output_parser = StrOutputParser()\n",
    "\n",
    "        # 체인 만들기\n",
    "        self.chain = prompt | model | output_parser\n",
    "\n",
    "\n",
    "    def _save_memory(self, input, output):\n",
    "            self.memory.save_context(\n",
    "            {\"inputs\": input},\n",
    "            {\"output\": output}\n",
    "        )\n",
    "\n",
    "    async def astream(self, input):\n",
    "        self.inputs[\"input\"] = input\n",
    "\n",
    "        output = \"\"\n",
    "        result = self.chain.astream(self.inputs)\n",
    "        async for token in result:\n",
    "            output += token \n",
    "            # 소켓 통신 코드 \n",
    "            print(token, end=\"\", flush=True)\n",
    "        \n",
    "        # 메모리에 저장\n",
    "        self._save_memory(input, output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722056545.034850 5325681 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n",
      "I0000 00:00:1722056545.044810 5325681 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1722056545.046802 5325681 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    }
   ],
   "source": [
    "chain = GeminiChain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hello'),\n",
       " AIMessage(content='Hi'),\n",
       " HumanMessage(content=\"I'm so happy\")]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "\n",
    "# 날짜(log_create_at) 내림차순\n",
    "logs = [\n",
    "    {\"role\":\"user\", \"contents\":\"hello\"},\n",
    "    {\"role\":\"character\", \"contents\":\"Hi\"},\n",
    "    {\"role\":\"user\", \"contents\":\"I'm so happy\"},\n",
    "]\n",
    "\n",
    "chat_history = []\n",
    "for log in logs:\n",
    "    if log[\"role\"] == \"user\":\n",
    "        chat = HumanMessage(log[\"contents\"])\n",
    "    else:\n",
    "        chat = AIMessage(log[\"contents\"])\n",
    "    \n",
    "    chat_history.append(chat)\n",
    "\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "atlas로 관리하기: [MongoDB Atlas 평생 무료로 사용해보기](https://it-creamstory.tistory.com/entry/MongoDB-Atlas-%ED%8F%89%EC%83%9D-%EB%AC%B4%EB%A3%8C%EB%A1%9C-%EC%82%AC%EC%9A%A9%ED%95%B4%EB%B3%B4%EA%B8%B0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터베이스 'emozis'에 연결되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# MongoDB 설치 후 사용 버전\n",
    "import os \n",
    "import urllib.parse\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# 사용자 정보\n",
    "username = urllib.parse.quote_plus(os.environ[\"MONGODB_USERNAME\"])\n",
    "password = urllib.parse.quote_plus(os.environ[\"MONGODB_PASSWORD\"])\n",
    "\n",
    "# MongoDB 호스트 및 포트 정보\n",
    "host = \"172.16.2.10\"\n",
    "port = 27017\n",
    "\n",
    "# MongoDB URI\n",
    "mongo_uri = f\"mongodb://{username}:{password}@{host}:{port}\"\n",
    "\n",
    "# MongoClient 생성\n",
    "client = MongoClient(mongo_uri)\n",
    "\n",
    "# 데이터베이스 이름\n",
    "database_name = \"emozis\"\n",
    "\n",
    "# 데이터베이스 선택\n",
    "db = client[database_name]\n",
    "\n",
    "# 연결 확인\n",
    "print(f\"데이터베이스 '{database_name}'에 연결되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터베이스 'emozis'에 연결되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# Atlas Version\n",
    "import os \n",
    "import urllib.parse\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# 사용자 정보\n",
    "username = urllib.parse.quote_plus(os.environ[\"MONGODB_USERNAME\"])\n",
    "password = urllib.parse.quote_plus(os.environ[\"MONGODB_PASSWORD\"])\n",
    "\n",
    "# MongoDB 호스트 및 포트 정보\n",
    "host = \"cluster0.urikuvt.mongodb.net\"\n",
    "\n",
    "# MongoDB URI\n",
    "mongo_uri = f\"mongodb+srv://{username}:{password}@{host}\"\n",
    "\n",
    "# MongoClient 생성\n",
    "client = MongoClient(mongo_uri)\n",
    "\n",
    "# 데이터베이스 이름\n",
    "database_name = \"emozis\"\n",
    "\n",
    "# 데이터베이스 선택\n",
    "db = client[database_name]\n",
    "\n",
    "# 연결 확인\n",
    "print(f\"데이터베이스 '{database_name}'에 연결되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_mflix', 'admin', 'local']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# client의 모든 데이터베이스 조회\n",
    "client.list_database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['ac-feuml5i-shard-00-01.urikuvt.mongodb.net:27017', 'ac-feuml5i-shard-00-02.urikuvt.mongodb.net:27017', 'ac-feuml5i-shard-00-00.urikuvt.mongodb.net:27017'], document_class=dict, tz_aware=False, connect=True, authsource='admin', replicaset='atlas-t7l5oj-shard-0', tls=True), 'emozis'), 'project')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 컬렉션 생성\n",
    "collection_name = \"project\"\n",
    "db.create_collection(collection_name)   # 생성\n",
    "# db.drop_collection(collection_name)   # 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터베이스의 모든 컬렉션 조회\n",
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['ac-feuml5i-shard-00-01.urikuvt.mongodb.net:27017', 'ac-feuml5i-shard-00-02.urikuvt.mongodb.net:27017', 'ac-feuml5i-shard-00-00.urikuvt.mongodb.net:27017'], document_class=dict, tz_aware=False, connect=True, authsource='admin', replicaset='atlas-t7l5oj-shard-0', tls=True), 'emozis'), 'project')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = db[\"project\"]\n",
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted document ID: 66aba359133700f1dc2abdc4\n"
     ]
    }
   ],
   "source": [
    "# 문서 추가\n",
    "# 단일 문서 삽입\n",
    "document = {\"name\": \"Alice\", \"age\": 30, \"city\": \"New York\"}\n",
    "insert_result = collection.insert_one(document)\n",
    "print(f\"Inserted document ID: {insert_result.inserted_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted document IDs: [ObjectId('66aba35b133700f1dc2abdc5'), ObjectId('66aba35b133700f1dc2abdc6')]\n"
     ]
    }
   ],
   "source": [
    "# 다중 문서 삽입\n",
    "documents = [\n",
    "    {\"name\": \"Bob\", \"age\": 25, \"city\": \"Los Angeles\"},\n",
    "    {\"name\": \"Charlie\", \"age\": 35, \"city\": \"Chicago\"},\n",
    "]\n",
    "insert_many_result = collection.insert_many(documents)\n",
    "print(f\"Inserted document IDs: {insert_many_result.inserted_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('66aba359133700f1dc2abdc4'), 'name': 'Alice', 'age': 30, 'city': 'New York'}\n",
      "{'_id': ObjectId('66aba35b133700f1dc2abdc5'), 'name': 'Bob', 'age': 25, 'city': 'Los Angeles'}\n",
      "{'_id': ObjectId('66aba35b133700f1dc2abdc6'), 'name': 'Charlie', 'age': 35, 'city': 'Chicago'}\n"
     ]
    }
   ],
   "source": [
    "# 모든 문서 조회\n",
    "all_documents = collection.find()\n",
    "for doc in all_documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('66aba35b133700f1dc2abdc6'), 'name': 'Charlie', 'age': 35, 'city': 'Chicago'}\n"
     ]
    }
   ],
   "source": [
    "# 특정 조건의 문서 조회\n",
    "query = {\"age\": {\"$gt\": 30}}  # 나이가 30보다 큰 문서 조회\n",
    "filtered_documents = collection.find(query)\n",
    "for doc in filtered_documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched documents: 1, Updated documents: 1\n"
     ]
    }
   ],
   "source": [
    "# 단일 문서 업데이트\n",
    "query = {\"name\": \"Alice\"}\n",
    "new_values = {\"$set\": {\"age\": 31}}\n",
    "update_result = collection.update_one(query, new_values)\n",
    "print(f\"Matched documents: {update_result.matched_count}, Updated documents: {update_result.modified_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched documents: 1, Updated documents: 1\n"
     ]
    }
   ],
   "source": [
    "# 다중 문서 업데이트\n",
    "query = {\"city\": \"Los Angeles\"}\n",
    "new_values = {\"$set\": {\"city\": \"San Francisco\"}}\n",
    "update_many_result = collection.update_many(query, new_values)\n",
    "print(f\"Matched documents: {update_many_result.matched_count}, Updated documents: {update_many_result.modified_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted documents: 1\n"
     ]
    }
   ],
   "source": [
    "# 단일 문서 삭제\n",
    "query = {\"name\": \"Alice\"}\n",
    "delete_result = collection.delete_one(query)\n",
    "print(f\"Deleted documents: {delete_result.deleted_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted documents: 1\n"
     ]
    }
   ],
   "source": [
    "# 다중 문서 삭제\n",
    "query = {\"city\": \"San Francisco\"}\n",
    "delete_many_result = collection.delete_many(query)\n",
    "print(f\"Deleted documents: {delete_many_result.deleted_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('66aba35b133700f1dc2abdc6'), 'name': 'Charlie', 'age': 35, 'city': 'Chicago'}\n"
     ]
    }
   ],
   "source": [
    "# 모든 문서 조회\n",
    "all_documents = collection.find()\n",
    "for doc in all_documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeleteResult({'n': 1, 'electionId': ObjectId('7fffffff00000000000000c0'), 'opTime': {'ts': Timestamp(1722524581, 1), 't': 192}, 'ok': 1.0, '$clusterTime': {'clusterTime': Timestamp(1722524581, 2), 'signature': {'hash': b'\\x1e 6\\xc1P;\\x96\\x8d\\xeele\\x14\\xe6\\xf217\\xf3a^7', 'keyId': 7340700305501192197}}, 'operationTime': Timestamp(1722524581, 1)}, acknowledged=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 문서 삭제\n",
    "collection.delete_many({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 삽입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'category': 'AI',\n",
       "  'start_date': '2024-07-10T00:00:00.000',\n",
       "  'end_date': '2024-08-05T00:00:00.000',\n",
       "  'content': '🪄 프롬프트 업데이트\\n\\n✅ 시어머니 \\n✅ 인사이드아웃\\n✅ 여사친\\n✅ 남사친',\n",
       "  'status': '🔴 진행중'},\n",
       " {'category': 'AI',\n",
       "  'start_date': '2024-07-10T00:00:00.000',\n",
       "  'end_date': '2024-08-05T00:00:00.000',\n",
       "  'content': '🪄 Demo 페이지 구현\\n\\n✅ 프롬프트 선택 가능, 직접 입력 가능\\n✅ 챗봇 구현 (오류 해결)\\n➕ 503 error 자동 API 재요청 코드로 전환\\n➕ 충돌 방지를 위해 프롬프트 편집 폴더를 따로 분리',\n",
       "  'status': '🟢 완료'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "\n",
    "with open(\"../data_frame.json\", 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsertManyResult([ObjectId('66aba3fc133700f1dc2abdc7'), ObjectId('66aba3fc133700f1dc2abdc8'), ObjectId('66aba3fc133700f1dc2abdc9'), ObjectId('66aba3fc133700f1dc2abdca'), ObjectId('66aba3fc133700f1dc2abdcb'), ObjectId('66aba3fc133700f1dc2abdcc'), ObjectId('66aba3fc133700f1dc2abdcd'), ObjectId('66aba3fc133700f1dc2abdce'), ObjectId('66aba3fc133700f1dc2abdcf'), ObjectId('66aba3fc133700f1dc2abdd0'), ObjectId('66aba3fc133700f1dc2abdd1'), ObjectId('66aba3fc133700f1dc2abdd2'), ObjectId('66aba3fc133700f1dc2abdd3'), ObjectId('66aba3fc133700f1dc2abdd4'), ObjectId('66aba3fc133700f1dc2abdd5'), ObjectId('66aba3fc133700f1dc2abdd6'), ObjectId('66aba3fc133700f1dc2abdd7')], acknowledged=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.insert_many(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
