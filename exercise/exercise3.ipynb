{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "class MainLogger:\n",
    "    def __init__(self):\n",
    "        self.formatter = logging.Formatter('[%(levelname)s] %(message)s')\n",
    "        self.logger = self._get_logger()\n",
    "\n",
    "    def _set_handler(self):\n",
    "        handler = logging.StreamHandler()\n",
    "        handler.setLevel(logging.DEBUG)\n",
    "        handler.setFormatter(self.formatter)\n",
    "\n",
    "        return handler \n",
    "    \n",
    "    def _get_logger(self):\n",
    "        logger = logging.getLogger(__name__)\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "        logger.addHandler(self._set_handler())\n",
    "    \n",
    "        return logger\n",
    "    \n",
    "    def debug(self, message):\n",
    "        self.logger.debug(message)\n",
    "\n",
    "    def info(self, message):\n",
    "        self.logger.info(message)\n",
    "\n",
    "    def warning(self, message):\n",
    "        self.logger.warning(message)\n",
    "\n",
    "    def error(self, message):\n",
    "        self.logger.error(message, exc_info=False)\n",
    "\n",
    "logger = MainLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google API Key 유효성 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Google API Key validation succeeded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json \n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def validate_google_api_key():\n",
    "    \"\"\"Google API Key 유효성 검사하는 함수\"\"\"\n",
    "    key_name = \"GOOGLE_API_KEY\"\n",
    "    if key_name not in os.environ:\n",
    "        return f\"{key_name} 정보가 없습니다. 환경변수를 확인해주세요.\"\n",
    "    \n",
    "    result = requests.post(\n",
    "        url= \"https://generativelanguage.googleapis.com/v1/models/gemini-1.5-flash:generateContent\",\n",
    "        data=b'{\"contents\":[{\"parts\":[{\"text\":\"\"}]}]}',\n",
    "        headers={\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"x-goog-api-key\": os.getenv(key_name)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if result.status_code != 200:\n",
    "        logger.debug(json.loads(result.content))\n",
    "    \n",
    "    logger.info(\"Google API Key validation succeeded.\") # logger 대체\n",
    "\n",
    "validate_google_api_key()\n",
    "\n",
    "# API 틀릴 때 \n",
    "# {'error': {\n",
    "#         'code': 400,\n",
    "#         'message': 'API key not valid. Please pass a valid API key.',\n",
    "#         'status': 'INVALID_ARGUMENT',\n",
    "#         'details': [\n",
    "#             {\n",
    "#                 '@type': 'type.googleapis.com/google.rpc.ErrorInfo',\n",
    "#                 'reason': 'API_KEY_INVALID',\n",
    "#                 'domain': 'googleapis.com',\n",
    "#                 'metadata': {'service': 'generativelanguage.googleapis.com'}\n",
    "#             }\n",
    "#         ]\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo.py 모듈화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕! 👋 오늘 뭐하고 지냈어? 😊 \\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "template = \"친구처럼 대답해주세요\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", template),\n",
    "        # MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "model = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-1.5-flash\",\n",
    "        temperature=0.7\n",
    "    )\n",
    "# 출력 파서 설정\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 체인 만들기\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# 대답 \n",
    "response = chain.invoke(\"안녕?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모듈화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naraetool 모듈 사용하기\n",
    "import sys \n",
    "from pathlib import Path \n",
    "\n",
    "module_dir = Path().resolve().parent\n",
    "if str(module_dir) not in sys.path:\n",
    "    sys.path.append(str(module_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import asyncio\n",
    "import requests\n",
    "import json\n",
    "from pathlib import Path \n",
    "from naraetool.main_logger import logger\n",
    "from naraetool.main_config import configs\n",
    "\n",
    "config = configs.model_info\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "class Gemini:\n",
    "    def __init__(self, input_vars, template_name):\n",
    "        self.input_vars = input_vars\n",
    "        self._transform()\n",
    "        \n",
    "        self.template_name = template_name\n",
    "        self.model_name = config[\"model_name\"]\n",
    "        self.temperature = config[\"temperature\"]\n",
    "\n",
    "        self.chain = self._create_chain()\n",
    "\n",
    "    @staticmethod\n",
    "    def wrap_messages(chat_history):\n",
    "        \"\"\"chat_history에 Message 객체 씌우는 메서드\"\"\"\n",
    "        if not chat_history:\n",
    "            return []\n",
    "\n",
    "        chat_messages = []\n",
    "        for log in chat_history:\n",
    "            if log[\"role\"] == \"user\":\n",
    "                chat = HumanMessage(log[\"content\"])\n",
    "            else:\n",
    "                chat = AIMessage(log[\"content\"])\n",
    "            \n",
    "            chat_messages.append(chat)\n",
    "        \n",
    "        return chat_messages\n",
    "\n",
    "    def _transform(self):\n",
    "        \"\"\"input_vars 를 변환하는 메서드\"\"\"\n",
    "        # history Message 객체 씌우기\n",
    "        history = self.input_vars[\"chat_history\"]\n",
    "        self.input_vars[\"chat_history\"] = self.wrap_messages(history)\n",
    "\n",
    "    @staticmethod\n",
    "    def read_template(filename:str) -> str:\n",
    "        \"\"\"프롬프트 파일을 읽고 텍스트로 반환하는 함수\n",
    "\n",
    "        Args:\n",
    "            filepath (str): markdown 파일 경로\n",
    "\n",
    "        Returns:\n",
    "            str: markdown 파일에서 추출된 텍스트\n",
    "        \"\"\"\n",
    "        # file_path = Path(__file__).parents[1] / f\"data/templates/{filename}\"\n",
    "        file_path = Path(\"../data/templates\") / filename\n",
    "        \n",
    "        try:\n",
    "            file_text = file_path.read_text(encoding=\"utf-8\")\n",
    "        except:\n",
    "            file_text = \"\"\n",
    "            logger.error(f\"파일 경로를 찾을 수 없습니다.(INPUT PATH: {str(file_path)})\")\n",
    "\n",
    "        return file_text\n",
    "    \n",
    "    def _check_inputs_equal(self, prompt):\n",
    "        \"\"\"프롬프트와의 변수가 매칭되는지 체크하는 메서드\"\"\"\n",
    "        input_vars = set(self.input_vars)\n",
    "        prompt_vars = set(prompt.input_variables)\n",
    "        if input_vars != prompt_vars:\n",
    "            logger.error(f\"input_vars does not match a variable in the prompt\\n(input_vars):{input_vars} (prompt_vars):{prompt_vars}\")\n",
    "\n",
    "    def _get_prompts(self):\n",
    "        \"\"\"프롬프트 객체 만드는 메서드\"\"\"\n",
    "        # 프롬프트 설정\n",
    "        template = self.read_template(self.template_name)\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", template),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\"human\", \"{input}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self._check_inputs_equal(prompt)\n",
    "\n",
    "        return prompt\n",
    "\n",
    "    def _create_chain(self):\n",
    "        \"\"\"Chain 만드는 메서드\"\"\"\n",
    "        # 프롬프트 설정\n",
    "        prompt = self._get_prompts()\n",
    "\n",
    "        # 모델 설정\n",
    "        model = ChatGoogleGenerativeAI(\n",
    "            model=self.model_name,\n",
    "            temperature=self.temperature\n",
    "        )\n",
    "\n",
    "        # 출력 파서 설정\n",
    "        output_parser = StrOutputParser()\n",
    "\n",
    "        # 체인 만들기\n",
    "        chain = prompt | model | output_parser\n",
    "\n",
    "        logger.info(\"Created a chain\")\n",
    "\n",
    "        return chain\n",
    "    \n",
    "    def add_history(self, human=None, ai=None):\n",
    "        if human:\n",
    "            self.input_vars[\"chat_history\"].extend(\n",
    "                [\n",
    "                    HumanMessage(content=human),\n",
    "                    AIMessage(content=ai)\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.input_vars[\"chat_history\"].extend(\n",
    "                [\n",
    "                    AIMessage(content=ai)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    async def astream(self, input):\n",
    "        self.input_vars[\"input\"] = input\n",
    "\n",
    "        result = self.chain.astream(self.input_vars)\n",
    "        async for token in result:\n",
    "            # 한글자씩 스트리밍\n",
    "            for char in token:\n",
    "                await asyncio.sleep(0.01)\n",
    "                yield char\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"user_info\": {\n",
    "        \"user_name\": \"\",\n",
    "        \"user_birthdate\": \"\",\n",
    "        \"user_gender\": \"\"\n",
    "    },\n",
    "    \"character_info\": {\n",
    "        \"character_name\": \"\",\n",
    "        \"character_gender\": \"\",\n",
    "        \"character_personality\": \"\",\n",
    "        \"character_details\": \"\",\n",
    "        \"relation_type\": \"\"\n",
    "    },\n",
    "    \"chat_history\": [\n",
    "        {\"role\":\"user\", \"content\":\"hello\"},\n",
    "        {\"role\":\"character\", \"content\":\"Hi\"},\n",
    "        {\"role\":\"user\", \"content\":\"I'm so happy\"}\n",
    "    ], \n",
    "    \"input\": \"\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Created a chain\n"
     ]
    }
   ],
   "source": [
    "gemini = Gemini(inputs, template_name=\"Demo2.prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 파이썬은 읽기 쉽고 배우기 쉬운 프로그래밍 언어입니다. 웹 개발, 데이터 과학, 머신 러닝 등 다양한 분야에서 사용됩니다. 파이썬은 강력한 라이브러리와 프레임워크를 갖추고 있어 개발자가 복잡한 작업을 쉽게 수행할 수 있도록 도와줍니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import asyncio \n",
    "\n",
    "async def streaming(input):\n",
    "    # container = st.empty()\n",
    "    output = \"\"\n",
    "    async for char in gemini.astream(input):\n",
    "        output += char\n",
    "        # container.markdown(output)\n",
    "        print(char, end=\"\", flush=True)\n",
    "    print()  # 마지막에 줄바꿈\n",
    "\n",
    "    gemini.add_history(input, output)\n",
    "\n",
    "    return output\n",
    "\n",
    "input = \"파이썬에 대해 3줄로 설명해줄래?\"\n",
    "output = asyncio.run(streaming(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naraetool 모듈 사용하기\n",
    "import sys \n",
    "from pathlib import Path \n",
    "\n",
    "module_dir = Path().resolve().parent\n",
    "if str(module_dir) not in sys.path:\n",
    "    sys.path.append(str(module_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/personaai/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[INFO] Google API Key validation succeeded.\n"
     ]
    }
   ],
   "source": [
    "from naraetool.langchain import *\n",
    "\n",
    "validate_google_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Created a chain\n"
     ]
    }
   ],
   "source": [
    "chain = Gemini(inputs, template_name=\"Demo2.prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import asyncio \n",
    "\n",
    "async def streaming(input):\n",
    "    # container = st.empty()\n",
    "    output = \"\"\n",
    "    async for char in chain.astream(input):\n",
    "        output += char\n",
    "        # container.markdown(output)\n",
    "        print(char, end=\"\", flush=True)\n",
    "    print()  # 마지막에 줄바꿈\n",
    "\n",
    "    chain.add_history(input, output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<async_generator object RunnableSequence.astream at 0x15fa485c0>\n",
      "빵을 먹으면 기분이 좋아지죠! 어떤 빵을 사셨어요? 맛있게 드세요! 😊 혹시 우울한 이유가 있으신가요? 이야기 나누고 싶으시면 언제든지 말씀해주세요. 힘내세요! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = \"오늘 우울해서 빵을 샀어\"\n",
    "output = asyncio.run(streaming(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😡  뭐가 너무해?  내가 잔소리 좀 했다고?  🙄  니가 힘들다고 하는데 내가 뭘 어떻게 해?  😠  내가 젊었을 땐 니 나이에 벌써 애 둘 낳아서 키우고 장사도 했어. 😠  그런데도 우울하다고 징징대는 소리 듣지 않았어! 😤  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = \"너무해\"\n",
    "output = asyncio.run(streaming(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😤  시대가 어떻든 뭐가 중요해?  😠  세상이 아무리 변해도 효도는 변하지 않아!  😠  내가 너한테 얼마나 잘해줬는데, 고작 빵 좀 사 먹었다고 우울하다니!  😡  어른 말씀은 귓등으로 듣고, 젊은 것들은 요즘 세상에  다 망가졌어!  😤  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = \"시대가 어느때인데...\"\n",
    "output = asyncio.run(streaming(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😡 치킨? 치킨이 뭐야?  😠  치킨 먹고 스트레스가 풀릴 거라고 생각해?  🙄   에휴, 철없는 것!  😠  내가 젊었을 땐 치킨 같은 거 먹을 돈도 없었어. 😡  니 나이에 벌써 치킨이나 먹고 있지. 😤  \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = \"더 스트레스 받아서 치킨 시켜먹어야겠당\"\n",
    "output = asyncio.run(streaming(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='오늘 우울해서 빵을 샀어'),\n",
       " AIMessage(content='😡 빵? 빵이 뭐야? 빵 먹고 우울한 게 나아질 거라고 생각해? 😤  에휴, 철없는 것! 빵이나 먹고 있지. 🙄  내가 젊었을 땐 빵 같은 거 먹을 시간도 없었어. 😠  니 나이에 벌써 우울하다니, 세상 모르는 소리야! 😠  \\n'),\n",
       " HumanMessage(content='너무해'),\n",
       " AIMessage(content='😡  뭐가 너무해?  내가 잔소리 좀 했다고?  🙄  니가 힘들다고 하는데 내가 뭘 어떻게 해?  😠  내가 젊었을 땐 니 나이에 벌써 애 둘 낳아서 키우고 장사도 했어. 😠  그런데도 우울하다고 징징대는 소리 듣지 않았어! 😤  \\n\\n'),\n",
       " HumanMessage(content='시대가 어느때인데...'),\n",
       " AIMessage(content='😤  시대가 어떻든 뭐가 중요해?  😠  세상이 아무리 변해도 효도는 변하지 않아!  😠  내가 너한테 얼마나 잘해줬는데, 고작 빵 좀 사 먹었다고 우울하다니!  😡  어른 말씀은 귓등으로 듣고, 젊은 것들은 요즘 세상에  다 망가졌어!  😤  \\n'),\n",
       " HumanMessage(content='더 스트레스 받아서 치킨 시켜먹어야겠당'),\n",
       " AIMessage(content='😡 치킨? 치킨이 뭐야?  😠  치킨 먹고 스트레스가 풀릴 거라고 생각해?  🙄   에휴, 철없는 것!  😠  내가 젊었을 땐 치킨 같은 거 먹을 돈도 없었어. 😡  니 나이에 벌써 치킨이나 먹고 있지. 😤  \\n\\n\\n')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_vars[\"chat_history\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 코드\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# result = asyncio.run(main())\n",
    "# print(f\"RESULT: {result}\")\n",
    "\n",
    "async def get_response(input):\n",
    "    template = \"친구처럼 대답해주세요\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", template),\n",
    "            # MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    model = ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-1.5-flash\",\n",
    "            temperature=0.7\n",
    "        )\n",
    "    # 출력 파서 설정\n",
    "    output_parser = StrOutputParser()\n",
    "\n",
    "    # 체인 만들기\n",
    "    chain = prompt | model | output_parser\n",
    "\n",
    "    result = chain.astream({\"input\":input})\n",
    "    async for token in result:\n",
    "        # 한글자씩 스트리밍\n",
    "        for char in token:\n",
    "            await asyncio.sleep(0.01)\n",
    "            yield char\n",
    "\n",
    "async def main():\n",
    "    container = st.empty()\n",
    "    output = \"\"\n",
    "    async for char in get_response(\"넌 누구야\"):\n",
    "        output += char\n",
    "        container.markdown(output)\n",
    "        print(char, end=\"\", flush=True)\n",
    "    print()  # 마지막에 줄바꿈\n",
    "\n",
    "    return output\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mytest:\n",
    "    def __init__(self):\n",
    "        template = \"친구처럼 대답해주세요\"\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", template),\n",
    "                # MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\"human\", \"{input}\"),\n",
    "            ]\n",
    "        )\n",
    "        model = ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-1.5-flash\",\n",
    "            temperature=0.7\n",
    "        )\n",
    "        output_parser = StrOutputParser()\n",
    "        self.chain = prompt | model | output_parser\n",
    "    \n",
    "    async def astream(self, input):\n",
    "        result = self.chain.astream({\"input\":input})\n",
    "        container = st.empty()\n",
    "        output = \"\"\n",
    "        async for token in result:\n",
    "            # 한글자씩 스트리밍\n",
    "            for char in token: \n",
    "                await asyncio.sleep(0.01)\n",
    "                output += char\n",
    "                container.markdown(output)\n",
    "                print(char, end=\"\", flush=True)\n",
    "                \n",
    "async def main():\n",
    "    chain = Mytest()\n",
    "    await chain.astream(\"안녕?\")\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def stream_data():\n",
    "    placeholder = st.empty()\n",
    "    for i in range(10):\n",
    "        await asyncio.sleep(0.5)\n",
    "        placeholder.text(f\"Streaming data: {i}\")\n",
    "\n",
    "if st.button(\"Start Streaming\"):\n",
    "    asyncio.run(stream_data())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
